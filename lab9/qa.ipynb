{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marcin Wardyński  \n",
    "czwartek, 8:00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dla przygotowania danych treningowych i walidacyjnych dla modelu trzeba przerobić istniejące pliki json. Format nowych plików powininen zawierać elementy:\n",
    "- id\n",
    "- title\n",
    "- context\n",
    "- question\n",
    "- generative_answer\n",
    "- is_impossible\n",
    "a każdy element powinien zawierać się w pojedyńczym wierszu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def convert_data(data):\n",
    "    results = []\n",
    "    i = 0\n",
    "    for article in data.get(\"data\", []):\n",
    "        for paragraph in article.get(\"paragraphs\", []):\n",
    "            context = paragraph[\"context\"]\n",
    "            for qa in paragraph[\"qas\"]:\n",
    "                question = qa[\"question\"]\n",
    "                answers = qa['answers'] if 'answers' in qa.keys() else qa['plausible_answers']\n",
    "                for answer in answers:\n",
    "                    i += 1\n",
    "                    results.append({\n",
    "                        \"id\": i,\n",
    "                        \"context\": context,\n",
    "                        \"question\": question,\n",
    "                        \"answers\": {\n",
    "                            \"text\": [answer[\"generative_answer\"]]\n",
    "                        }\n",
    "                    })\n",
    "    return results\n",
    "\n",
    "\n",
    "def convert_format(input_filepath, output_filepath):\n",
    "    with open(input_filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    output_data = convert_data(data)\n",
    "    output_wrapped_data = {\"version\": \"0.1.0\", \"data\": output_data}\n",
    "\n",
    "    with open(output_filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(output_wrapped_data, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_format(\"poquad-train.json\", \"poquad-conv-train.json\")\n",
    "convert_format(\"poquad-dev.json\", \"poquad-conv-dev.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python run_seq2seq_qa.py \\\n",
    "  --model_name_or_path allegro/plt5-base \\\n",
    "  --dataset_name clarin-pl/poquad \\\n",
    "  --context_column context \\\n",
    "  --question_column question \\\n",
    "  --answer_column answers \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --per_device_train_batch_size 12 \\\n",
    "  --learning_rate 3e-5 \\\n",
    "  --num_train_epochs 3 \\\n",
    "  --max_seq_length 384 \\\n",
    "  --doc_stride 128 \\\n",
    "  --output_dir ../../../../model_poquad_extr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python run_seq2seq_qa.py \\\n",
    "  --model_name_or_path allegro/plt5-base \\\n",
    "  --train_file /Users/mwardynski/Documents/ds/_semestr_9/przetwarzanie_jezyka_naturalnego/labs/lab9/poquad-conv-train.json \\\n",
    "  --validation_file /Users/mwardynski/Documents/ds/_semestr_9/przetwarzanie_jezyka_naturalnego/labs/lab9/poquad-conv-dev.json \\\n",
    "  --context_column context \\\n",
    "  --question_column question \\\n",
    "  --answer_column answers \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --per_device_train_batch_size 12 \\\n",
    "  --learning_rate 3e-5 \\\n",
    "  --num_train_epochs 3 \\\n",
    "  --max_seq_length 384 \\\n",
    "  --doc_stride 128 \\\n",
    "  --output_dir ../../../../model_poquad_abstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "ready_model_name = \"apohllo/plt5-base-poquad\"\n",
    "ready_model_tokenizer = AutoTokenizer.from_pretrained(ready_model_name)\n",
    "ready_model = AutoModelForSeq2SeqLM.from_pretrained(ready_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Czy żołnierz, który dopuszcza się czynnej napaści na przełożonego podlega karze pozbawienia wolności?\n",
      "Answer: tak\n"
     ]
    }
   ],
   "source": [
    "context = \"Art. 345. § 1. Żołnierz, który dopuszcza się czynnej napaści na przełożonego, podlega karze aresztu wojskowego albo pozbawienia wolności do lat 3. § 2. Jeżeli sprawca dopuszcza się czynnej napaści w związku z pełnieniem przez przełożonego obowiązków służbowych albo wspólnie z innymi żołnierzami lub w obecności zebranych żołnierzy, podlega karze pozbawienia wolności od 6 miesięcy do lat 8. § 3. Jeżeli sprawca czynu określonego w § 1 lub 2 używa broni, noża lub innego podobnie niebezpiecznego przedmiotu, podlega karze pozbawienia wolności od roku do lat 10. § 4. Karze przewidzianej w § 3 podlega sprawca czynu określonego w § 1 lub 2, jeżeli jego następstwem jest skutek określony w art. 156 lub 157 § 1.\"\n",
    "question = \"Czy żołnierz, który dopuszcza się czynnej napaści na przełożonego podlega karze pozbawienia wolności?\"\n",
    "\n",
    "input_text = f\"question: {question} context: {context}\"\n",
    "\n",
    "inputs = ready_model_tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "outputs = ready_model.generate(inputs[\"input_ids\"], max_length=50, num_beams=5, early_stopping=True)\n",
    "\n",
    "answer = ready_model_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "NO_ANS = \"no_ans\"\n",
    "\n",
    "class QA:\n",
    "    def __init__(self, question_id, question, answer):\n",
    "        self.question_id = question_id\n",
    "        self.question = question\n",
    "        self.answer = answer\n",
    "\n",
    "class Entry:\n",
    "    def __init__(self, passage_id, passage_text, qas):\n",
    "        self.passage_id = passage_id\n",
    "        self.passage_text = passage_text\n",
    "        self.qas = qas\n",
    "\n",
    "def init_qas_with_answers(filepath):\n",
    "    qa_dict = {}\n",
    "    with open(filepath, \"r\") as file:\n",
    "        for line in file:\n",
    "            record = json.loads(line.strip())\n",
    "            \n",
    "            if \"score\" in record and record[\"score\"] == \"1\"\\\n",
    "                    and \"question-id\" in record and \"answer\" in record:\n",
    "                qa = QA(record[\"question-id\"], None, record[\"answer\"])\n",
    "                qa_dict[record[\"question-id\"]] = qa\n",
    "    return qa_dict\n",
    "\n",
    "def match_questions_to_answers(filepath, qa_dict):\n",
    "    q_wo_a = []\n",
    "    with open(filepath, \"r\") as file:\n",
    "        for line in file:\n",
    "            record = json.loads(line.strip())\n",
    "            \n",
    "            if \"text\" in record and \"_id\" in record:\n",
    "                if record[\"_id\"] in qa_dict.keys():\n",
    "                    qa = qa_dict[record[\"_id\"]]\n",
    "                    qa.question = record[\"text\"]\n",
    "                else:\n",
    "                    qa_dict[NO_ANS].append(record[\"text\"])\n",
    "\n",
    "\n",
    "def organize_question_to_context_relations(filepath, qa_dict):\n",
    "    qc_dict = {}\n",
    "    with open(filepath, \"r\") as file:\n",
    "        for line in file:\n",
    "            record = json.loads(line.strip())\n",
    "            \n",
    "            if \"score\" in record and record[\"score\"] == \"1\"\\\n",
    "                    and \"passage-id\" in record\\\n",
    "                    and \"question-id\" in record and record[\"question-id\"] in qa_dict.keys():\n",
    "                if record[\"passage-id\"] not in qc_dict.keys():\n",
    "                    qc_dict[record[\"passage-id\"]] = []\n",
    "                qc_dict[record[\"passage-id\"]].append(record[\"question-id\"])\n",
    "    return qc_dict\n",
    "\n",
    "def load_passages(filepath, qc_dict, qa_dict):\n",
    "    entries = []\n",
    "    with open(filepath, \"r\") as file:\n",
    "        for line in file:\n",
    "            record = json.loads(line.strip())\n",
    "            \n",
    "            if \"text\" in record and \"_id\" in record and record[\"_id\"] in qc_dict.keys():\n",
    "                qa_ids = qc_dict[record[\"_id\"]]\n",
    "                qas = []\n",
    "                for qa_id in qa_ids:\n",
    "                    qas.append(qa_dict[qa_id])\n",
    "                entries.append(Entry(record[\"_id\"], record[\"text\"], qas))\n",
    "    return entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_dict = init_qas_with_answers(\"simple-legal-questions-pl-main/answers.jl\")\n",
    "\n",
    "qa_dict[NO_ANS] = []\n",
    "match_questions_to_answers(\"simple-legal-questions-pl-main/questions.jl\", qa_dict)\n",
    "\n",
    "qc_dict = organize_question_to_context_relations(\"simple-legal-questions-pl-main/relevant.jl\", qa_dict)\n",
    "test_passages = load_passages(\"simple-legal-questions-pl-main/passages.jl\", qc_dict, qa_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_poquad_data(filepath):\n",
    "    val_entries = []\n",
    "    with open(filepath, \"r\") as file:\n",
    "        json_content = json.load(file)\n",
    "        for data in json_content['data']:\n",
    "            for paragraph in data['paragraphs']:\n",
    "                qa_list = []\n",
    "                for qa in paragraph['qas']:\n",
    "                    answers = qa['answers'] if 'answers' in qa.keys() else qa['plausible_answers']\n",
    "                    for answer in answers:\n",
    "                        qa_obj = QA(None, qa['question'], answer['generative_answer'])\n",
    "                        qa_list.append(qa_obj)\n",
    "                    \n",
    "                entry = Entry(None, paragraph['context'], qa_list)\n",
    "                val_entries.append(entry)\n",
    "    return val_entries\n",
    "\n",
    "val_passages = convert_poquad_data(\"poquad-dev.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def exec_passages(model, tokenizer, passages):\n",
    "    answers = []\n",
    "    expected_answers = []\n",
    "    for passage in tqdm(passages):\n",
    "        for qa in passage.qas:\n",
    "            input_text = f\"question: {qa.question} context: {passage.passage_text}\"\n",
    "            inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "            outputs = model.generate(inputs[\"input_ids\"], max_length=100, num_beams=5, early_stopping=True)\n",
    "\n",
    "            answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            answers.append(answer)\n",
    "            expected_answers.append(qa.answer)\n",
    "    return answers, expected_answers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_passages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [16:48<00:00,  1.81s/it]\n"
     ]
    }
   ],
   "source": [
    "answers, expected_answers = exec_passages(ready_model, ready_model_tokenizer, test_passages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "my_t5_base_model_name = \"./model_poquad_abstr\"\n",
    "my_t5_base_model_tokenizer = AutoTokenizer.from_pretrained(my_t5_base_model_name)\n",
    "my_t5_base_model = AutoModelForSeq2SeqLM.from_pretrained(ready_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [14:06<00:00,  1.52s/it]\n"
     ]
    }
   ],
   "source": [
    "my_answers, expected_answers = exec_passages(my_t5_base_model, my_t5_base_model_tokenizer, test_passages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tak',\n",
       " 'tak',\n",
       " 'tak',\n",
       " '1 stycznia',\n",
       " '5% miesięcznego wynagrodzenia zasadniczego',\n",
       " 'trzymiesięcznego wynagrodzenia']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tak',\n",
       " 'tak',\n",
       " 'tak',\n",
       " '1 stycznia',\n",
       " '5% miesięcznego wynagrodzenia zasadniczego',\n",
       " 'trzymiesięcznego wynagrodzenia']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tak, urzędnikiem może zostać osoba, która odbyła staż urzędniczy w prokuraturze',\n",
       " 'Tak, osoba, która cieszy się nieposzlakowaną opinią, może zostać urzędnikiem (zgodnie z ustawą o pracownikach samorządowych).',\n",
       " 'Tak',\n",
       " '1 stycznia każdego roku',\n",
       " 'Wysokość trzymiesięcznego wynagrodzenia',\n",
       " 'Pracownikowi sądu, który prawcował 15 lat w sądzie, przysługuje jednorazowa odprawa w wysokości trzymiesięcznego wynagrodzenia']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_exact_matches(answers, expected_answers):\n",
    "    matches = 0\n",
    "    for s1, s2 in zip(answers, expected_answers):\n",
    "        if s1.lower() == s2.lower():\n",
    "            matches += 1\n",
    "    return matches/len(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2456445993031359"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_exact_matches(my_answers, expected_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2456445993031359"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_exact_matches(answers, expected_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "# Sample data\n",
    "list1 = [\"the cat sat on the mat\", \"a dog barked loudly\", \"birds are singing\"]\n",
    "list2 = [\"cat is on the mat\", \"a dog howled loudly\", \"birds are chirping\"]\n",
    "\n",
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    tokens = re.split(r\"[^\\w]+\", text)\n",
    "    return tokens\n",
    "\n",
    "# Compute confusion matrix and F1 score based on token counts\n",
    "def compute_single_f1(tokens1, tokens2):\n",
    "    TP = sum((tokens1 & tokens2).values())\n",
    "    FP = sum((tokens1 - tokens2).values())\n",
    "    FN = sum((tokens2 - tokens1).values())\n",
    "\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    return f1\n",
    "\n",
    "def compute_f1(answers, expected_answers, tokenize_fun):\n",
    "\n",
    "    f1_scores = []\n",
    "    for s1, s2 in zip(answers, expected_answers):\n",
    "        s1_t = Counter(tokenize_fun(s1))\n",
    "        s2_t = Counter(tokenize_fun(s2))\n",
    "        f1 = compute_single_f1(s1_t, s2_t)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    return sum(f1_scores)/len(f1_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5184004475490456"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_f1(answers, expected_answers, tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_f1(my_answers, expected_answers, tokenize)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
