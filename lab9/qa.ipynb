{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marcin Wardyński  \n",
    "czwartek, 8:00\n",
    "\n",
    "## Lab 9: Kontekstowe odpowiadanie na pytania"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dla przygotowania danych treningowych i walidacyjnych dla modelu trzeba przerobić istniejące pliki json. Format nowych plików musi zawierać elementy:\n",
    "- `id`\n",
    "- `context`\n",
    "- `question`\n",
    "- `answers` z polem `text` zawierającym w postaci listy poprawne odpowiedzi\n",
    "\n",
    "Poniższa funkcja dokonuje oczekiwanego przekształcenia na zbiorze PoQuAD: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def convert_data(data):\n",
    "    results = []\n",
    "    i = 0\n",
    "    for article in data.get(\"data\", []):\n",
    "        for paragraph in article.get(\"paragraphs\", []):\n",
    "            context = paragraph[\"context\"]\n",
    "            for qa in paragraph[\"qas\"]:\n",
    "                question = qa[\"question\"]\n",
    "                answers = qa['answers'] if 'answers' in qa.keys() else qa['plausible_answers']\n",
    "                for answer in answers:\n",
    "                    i += 1\n",
    "                    results.append({\n",
    "                        \"id\": i,\n",
    "                        \"context\": context,\n",
    "                        \"question\": question,\n",
    "                        \"answers\": {\n",
    "                            \"text\": [answer[\"generative_answer\"]]\n",
    "                        }\n",
    "                    })\n",
    "    return results\n",
    "\n",
    "\n",
    "def convert_format(input_filepath, output_filepath):\n",
    "    with open(input_filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "    output_data = convert_data(data)\n",
    "    output_wrapped_data = {\"version\": \"0.1.0\", \"data\": output_data}\n",
    "\n",
    "    with open(output_filepath, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(output_wrapped_data, f, ensure_ascii=False, indent=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wywołuję powyższą funkcję i zapisuję przekształcone dane w plikach `poquad-conv-train.json` oraz `poquad-conv-dev.json` dla zbiorów treningowego i walidacyjnego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_format(\"poquad-train.json\", \"poquad-conv-train.json\")\n",
    "convert_format(\"poquad-dev.json\", \"poquad-conv-dev.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python run_seq2seq_qa.py \\\n",
    "  --model_name_or_path allegro/plt5-base \\\n",
    "  --dataset_name clarin-pl/poquad \\\n",
    "  --context_column context \\\n",
    "  --question_column question \\\n",
    "  --answer_column answers \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --per_device_train_batch_size 12 \\\n",
    "  --learning_rate 3e-5 \\\n",
    "  --num_train_epochs 3 \\\n",
    "  --max_seq_length 384 \\\n",
    "  --doc_stride 128 \\\n",
    "  --output_dir ../../../../model_poquad_extr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python run_seq2seq_qa.py \\\n",
    "  --model_name_or_path allegro/plt5-base \\\n",
    "  --train_file /Users/mwardynski/Documents/ds/_semestr_9/przetwarzanie_jezyka_naturalnego/labs/lab9/poquad-conv-train.json \\\n",
    "  --validation_file /Users/mwardynski/Documents/ds/_semestr_9/przetwarzanie_jezyka_naturalnego/labs/lab9/poquad-conv-dev.json \\\n",
    "  --context_column context \\\n",
    "  --question_column question \\\n",
    "  --answer_column answers \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --per_device_train_batch_size 12 \\\n",
    "  --learning_rate 3e-5 \\\n",
    "  --num_train_epochs 3 \\\n",
    "  --max_seq_length 384 \\\n",
    "  --doc_stride 128 \\\n",
    "  --output_dir ../../../../model_poquad_abstr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python run_seq2seq_qa.py \\\n",
    "  --model_name_or_path allegro/plt5-base \\\n",
    "  --train_file /Users/mwardynski/Documents/ds/_semestr_9/przetwarzanie_jezyka_naturalnego/labs/lab9/poquad-conv-train.json \\\n",
    "  --validation_file /Users/mwardynski/Documents/ds/_semestr_9/przetwarzanie_jezyka_naturalnego/labs/lab9/poquad-conv-dev.json \\\n",
    "  --context_column context \\\n",
    "  --question_column question \\\n",
    "  --answer_column answers \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --per_device_train_batch_size 16 \\\n",
    "  --learning_rate 2e-5 \\\n",
    "  --num_train_epochs 3 \\\n",
    "  --max_seq_length 384 \\\n",
    "  --doc_stride 128 \\\n",
    "  --output_dir ../../../../model_poquad_t5_base_2e-5_b16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "***** train metrics *****\n",
    "  epoch                    =                3.0\n",
    "  total_flos               =         86256742GF\n",
    "  train_loss               =             1.6838\n",
    "  train_runtime            = 2 days, 0:55:20.98\n",
    "  train_samples            =              56618\n",
    "  train_samples_per_second =              0.964\n",
    "  train_steps_per_second   =               0.06\n",
    "\n",
    "***** eval metrics *****\n",
    "  epoch                   =        3.0\n",
    "  eval_loss               =     0.9395\n",
    "  eval_runtime            = 0:06:16.18\n",
    "  eval_samples            =       7539\n",
    "  eval_samples_per_second =      20.04\n",
    "  eval_steps_per_second   =      2.507\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python run_seq2seq_qa.py \\\n",
    "  --model_name_or_path allegro/plt5-base \\\n",
    "  --train_file /Users/mwardynski/Documents/ds/_semestr_9/przetwarzanie_jezyka_naturalnego/labs/lab9/poquad-conv-train.json \\\n",
    "  --validation_file /Users/mwardynski/Documents/ds/_semestr_9/przetwarzanie_jezyka_naturalnego/labs/lab9/poquad-conv-dev-short.json \\\n",
    "  --context_column context \\\n",
    "  --question_column question \\\n",
    "  --answer_column answers \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --per_device_train_batch_size 16 \\\n",
    "  --learning_rate 4e-5 \\\n",
    "  --num_train_epochs 3 \\\n",
    "  --eval_strategy steps \\\n",
    "  --eval_steps 1 \\\n",
    "  --save_steps 500 \\\n",
    "  --metric_for_best_model f1 \\\n",
    "  --predict_with_generate True \\\n",
    "  --greater_is_better True \\\n",
    "  --load_best_model_at_end True \\\n",
    "  --save_total_limit 3 \\\n",
    "  --max_seq_length 384 \\\n",
    "  --doc_stride 128 \\\n",
    "  --output_dir ../../../../model_poquad_t5_base_f1_4e-5_b16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python run_seq2seq_qa.py \\\n",
    "  --model_name_or_path allegro/plt5-base \\\n",
    "  --train_file /Users/mwardynski/Documents/ds/_semestr_9/przetwarzanie_jezyka_naturalnego/labs/lab9/poquad-conv-train.json \\\n",
    "  --validation_file /Users/mwardynski/Documents/ds/_semestr_9/przetwarzanie_jezyka_naturalnego/labs/lab9/poquad-conv-dev.json \\\n",
    "  --context_column context \\\n",
    "  --question_column question \\\n",
    "  --answer_column answers \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --per_device_train_batch_size 16 \\\n",
    "  --learning_rate 4e-5 \\\n",
    "  --num_train_epochs 3 \\\n",
    "  --eval_strategy steps \\\n",
    "  --eval_steps 500 \\\n",
    "  --save_steps 500 \\\n",
    "  --predict_with_generate True \\\n",
    "  --metric_for_best_model f1 \\\n",
    "  --greater_is_better True \\\n",
    "  --load_best_model_at_end True \\\n",
    "  --save_total_limit 3 \\\n",
    "  --max_seq_length 384 \\\n",
    "  --doc_stride 128 \\\n",
    "  --output_dir ../../../../model_poquad_t5_base_f1_4e-5_b16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***** train metrics *****\n",
    "  epoch                    =        3.0\n",
    "  total_flos               = 86256742GF\n",
    "  train_loss               =     0.2784\n",
    "  train_runtime            = 8:25:03.53\n",
    "  train_samples            =      56618\n",
    "  train_samples_per_second =      5.605\n",
    "  train_steps_per_second   =       0.35\n",
    "\n",
    "***** eval metrics *****\n",
    "  epoch                   =        3.0\n",
    "  eval_exact_match        =    51.3881\n",
    "  eval_f1                 =    67.2528\n",
    "  eval_loss               =     0.8218\n",
    "  eval_runtime            = 0:39:08.28\n",
    "  eval_samples            =       7539\n",
    "  eval_samples_per_second =       3.21\n",
    "  eval_steps_per_second   =      0.402"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python run_seq2seq_qa.py \\\n",
    "  --model_name_or_path allegro/plt5-base \\\n",
    "  --train_file /Users/mwardynski/Documents/ds/_semestr_9/przetwarzanie_jezyka_naturalnego/labs/lab9/poquad-conv-train.json \\\n",
    "  --validation_file /Users/mwardynski/Documents/ds/_semestr_9/przetwarzanie_jezyka_naturalnego/labs/lab9/poquad-conv-dev.json \\\n",
    "  --context_column context \\\n",
    "  --question_column question \\\n",
    "  --answer_column answers \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --per_device_train_batch_size 8 \\\n",
    "  --learning_rate 2e-5 \\\n",
    "  --num_train_epochs 3 \\\n",
    "  --eval_strategy steps \\\n",
    "  --eval_steps 1000 \\\n",
    "  --save_steps 1000 \\\n",
    "  --predict_with_generate True \\\n",
    "  --metric_for_best_model f1 \\\n",
    "  --greater_is_better True \\\n",
    "  --load_best_model_at_end True \\\n",
    "  --save_total_limit 3 \\\n",
    "  --max_seq_length 384 \\\n",
    "  --doc_stride 128 \\\n",
    "  --output_dir ../../../../model_poquad_t5_base_f1_2e-5_b8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***** train metrics *****\n",
    "  epoch                    =         3.0\n",
    "  total_flos               =  86256742GF\n",
    "  train_loss               =      0.3401\n",
    "  train_runtime            = 13:55:17.07\n",
    "  train_samples            =       56618\n",
    "  train_samples_per_second =       3.389\n",
    "  train_steps_per_second   =       0.424\n",
    "\n",
    "***** eval metrics *****\n",
    "  epoch                   =        3.0\n",
    "  eval_exact_match        =    51.5297\n",
    "  eval_f1                 =    67.6208\n",
    "  eval_loss               =     0.8603\n",
    "  eval_runtime            = 0:41:46.65\n",
    "  eval_samples            =       7539\n",
    "  eval_samples_per_second =      3.008\n",
    "  eval_steps_per_second   =      0.376"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python run_seq2seq_qa.py \\\n",
    "  --model_name_or_path allegro/plt5-base \\\n",
    "  --train_file /Users/mwardynski/Documents/ds/_semestr_9/przetwarzanie_jezyka_naturalnego/labs/lab9/poquad-conv-train.json \\\n",
    "  --validation_file /Users/mwardynski/Documents/ds/_semestr_9/przetwarzanie_jezyka_naturalnego/labs/lab9/poquad-conv-dev.json \\\n",
    "  --context_column context \\\n",
    "  --question_column question \\\n",
    "  --answer_column answers \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --per_device_train_batch_size 16 \\\n",
    "  --learning_rate 5e-5 \\\n",
    "  --num_train_epochs 3 \\\n",
    "  --eval_strategy steps \\\n",
    "  --eval_steps 500 \\\n",
    "  --save_steps 500 \\\n",
    "  --predict_with_generate True \\\n",
    "  --metric_for_best_model f1 \\\n",
    "  --greater_is_better True \\\n",
    "  --load_best_model_at_end True \\\n",
    "  --save_total_limit 3 \\\n",
    "  --max_seq_length 384 \\\n",
    "  --doc_stride 128 \\\n",
    "  --output_dir ../../../../model_poquad_t5_base_f1_5e-5_b16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "***** train metrics *****\n",
    "  epoch                    =         3.0\n",
    "  total_flos               =  86256742GF\n",
    "  train_loss               =      0.3226\n",
    "  train_runtime            = 13:12:21.12\n",
    "  train_samples            =       56618\n",
    "  train_samples_per_second =       3.573\n",
    "  train_steps_per_second   =       0.223\n",
    "\n",
    "***** eval metrics *****\n",
    "  epoch                   =        3.0\n",
    "  eval_exact_match        =    52.3513\n",
    "  eval_f1                 =    68.3034\n",
    "  eval_loss               =     0.8013\n",
    "  eval_runtime            = 0:39:11.65\n",
    "  eval_samples            =       7539\n",
    "  eval_samples_per_second =      3.206\n",
    "  eval_steps_per_second   =      0.401\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "python run_seq2seq_qa.py \\\n",
    "  --model_name_or_path allegro/plt5-base \\\n",
    "  --train_file /Users/mwardynski/Documents/ds/_semestr_9/przetwarzanie_jezyka_naturalnego/labs/lab9/poquad-conv-train.json \\\n",
    "  --validation_file /Users/mwardynski/Documents/ds/_semestr_9/przetwarzanie_jezyka_naturalnego/labs/lab9/poquad-conv-dev.json \\\n",
    "  --context_column context \\\n",
    "  --question_column question \\\n",
    "  --answer_column answers \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --per_device_train_batch_size 12 \\\n",
    "  --learning_rate 3e-5 \\\n",
    "  --num_train_epochs 3 \\\n",
    "  --eval_strategy steps \\\n",
    "  --eval_steps 500 \\\n",
    "  --save_steps 500 \\\n",
    "  --predict_with_generate True \\\n",
    "  --metric_for_best_model f1 \\\n",
    "  --greater_is_better True \\\n",
    "  --load_best_model_at_end True \\\n",
    "  --save_total_limit 3 \\\n",
    "  --max_seq_length 384 \\\n",
    "  --doc_stride 128 \\\n",
    "  --output_dir ../../../../model_poquad_t5_base_f1_3e-5_b12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "***** train metrics *****\n",
    "  epoch                    =               3.0\n",
    "  total_flos               =        86256742GF\n",
    "  train_loss               =            1.2486\n",
    "  train_runtime            = 1 day, 4:45:16.29\n",
    "  train_samples            =             56618\n",
    "  train_samples_per_second =             1.641\n",
    "  train_steps_per_second   =             0.137\n",
    "\n",
    "***** eval metrics *****\n",
    "  epoch                   =        3.0\n",
    "  eval_exact_match        =    50.8499\n",
    "  eval_f1                 =    66.8706\n",
    "  eval_loss               =     0.8446\n",
    "  eval_runtime            = 0:47:32.25\n",
    "  eval_samples            =       7539\n",
    "  eval_samples_per_second =      2.643\n",
    "  eval_steps_per_second   =      0.331\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "ready_model_name = \"apohllo/plt5-base-poquad\"\n",
    "ready_model_tokenizer = AutoTokenizer.from_pretrained(ready_model_name)\n",
    "ready_model = AutoModelForSeq2SeqLM.from_pretrained(ready_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Czy żołnierz, który dopuszcza się czynnej napaści na przełożonego podlega karze pozbawienia wolności?\n",
      "Answer: tak\n"
     ]
    }
   ],
   "source": [
    "context = \"Art. 345. § 1. Żołnierz, który dopuszcza się czynnej napaści na przełożonego, podlega karze aresztu wojskowego albo pozbawienia wolności do lat 3. § 2. Jeżeli sprawca dopuszcza się czynnej napaści w związku z pełnieniem przez przełożonego obowiązków służbowych albo wspólnie z innymi żołnierzami lub w obecności zebranych żołnierzy, podlega karze pozbawienia wolności od 6 miesięcy do lat 8. § 3. Jeżeli sprawca czynu określonego w § 1 lub 2 używa broni, noża lub innego podobnie niebezpiecznego przedmiotu, podlega karze pozbawienia wolności od roku do lat 10. § 4. Karze przewidzianej w § 3 podlega sprawca czynu określonego w § 1 lub 2, jeżeli jego następstwem jest skutek określony w art. 156 lub 157 § 1.\"\n",
    "question = \"Czy żołnierz, który dopuszcza się czynnej napaści na przełożonego podlega karze pozbawienia wolności?\"\n",
    "\n",
    "input_text = f\"question: {question} context: {context}\"\n",
    "\n",
    "inputs = ready_model_tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "outputs = ready_model.generate(inputs[\"input_ids\"], max_length=50, num_beams=5, early_stopping=True)\n",
    "\n",
    "answer = ready_model_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do fine-tuningu swojego modelu użyłem nieznacznie zmienionego skryptu `run_seq2seq_qa.py` z repozytorium `transformers`, który został wywołany z następującymi parametrami:\n",
    "```\n",
    "  --model_name_or_path allegro/plt5-base \\\n",
    "  --train_file ../../../..poquad-conv-train.json \\\n",
    "  --validation_file ../../../..poquad-conv-dev.json \\\n",
    "  --context_column context \\\n",
    "  --question_column question \\\n",
    "  --answer_column answers \\\n",
    "  --do_train \\\n",
    "  --do_eval \\\n",
    "  --per_device_train_batch_size X \\\n",
    "  --learning_rate Ye-5 \\\n",
    "  --num_train_epochs 3 \\\n",
    "  --eval_strategy steps \\\n",
    "  --eval_steps 500 \\\n",
    "  --save_steps 500 \\\n",
    "  --predict_with_generate True \\\n",
    "  --metric_for_best_model f1 \\\n",
    "  --greater_is_better True \\\n",
    "  --load_best_model_at_end True \\\n",
    "  --save_total_limit 3 \\\n",
    "  --max_seq_length 384 \\\n",
    "  --doc_stride 128 \\\n",
    "  --output_dir ../../../../model_poquad_t5_base_f1_3e-5_b12\n",
    "```\n",
    "\n",
    "Jak widzimy powyżęj, jako modelu pretrenowanego używam `allegro/plt5-base`, gdyż moja konfiguracja komputera nie pozwala mi na wykorzystanie pojemniejszego modelu. Do treningu przekazuję uprzednio przygotowane pliki ze zbiorem danych PoQuAD oraz wskazuje nazwy odpowiednich kolumn. Zlecam wykonanie treningu i ewaluacji z wielkością batcha i krokiem treningu zdefiniowanym dla każdego uruchomienia skryptu z innymi wartościami. Trening ma trwać zalecane trzy epoki, a wybrana strategia ewaluacji `f1` powinna zostać uruchomiona co 500 kroków. Finalnie powinien zostać zaladowany model o najlepszym wyniku ewaluacji. Parametry `max_seq_length` oraz `doc_stride` otrzymały wartości odpowiednio 384 i 128. (Chociaż pierwsza z nich mogłaby w zasadzie otrzymać wartość 512)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wyniki skyptu dla wybranych parametrów treningowych:\n",
    "\n",
    "| lr   | #batch-y | eval em | eval f1 |\n",
    "|------|----------|---------|---------|\n",
    "| 2e-5 | 8        | 51.53   | 67.62   |\n",
    "| 3e-5 | 12       | 50.84   | 66.87   |\n",
    "| 4e-5 | 16       | 51.39   | 67.25   |\n",
    "| 5e-5 | 16       | 52.35   | 68.30   |\n",
    "\n",
    "Jak widzimy, dla danych walidacyjnych zbioru PoQuAD najlepiej wypada model o stałej uczącej `5e-5` i rozmiarze batch-a `16` i to zarówno dla metryki *Exact Match*, jak i *f1*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skoro mamy już wytrenowany model wraz z jego wstępną ewaluacją, skupmy się na danych testowych. Poniższy zestaw funkcji buduje struktury słownikowe, które ułatwiają nawigowanie po danych testowych zawierających wskazane pytania prawne:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "NO_ANS = \"no_ans\"\n",
    "\n",
    "class QA:\n",
    "    def __init__(self, question_id, question, answer):\n",
    "        self.question_id = question_id\n",
    "        self.question = question\n",
    "        self.answer = answer\n",
    "\n",
    "class Entry:\n",
    "    def __init__(self, passage_id, passage_text, qas):\n",
    "        self.passage_id = passage_id\n",
    "        self.passage_text = passage_text\n",
    "        self.qas = qas\n",
    "\n",
    "def init_qas_with_answers(filepath):\n",
    "    qa_dict = {}\n",
    "    with open(filepath, \"r\") as file:\n",
    "        for line in file:\n",
    "            record = json.loads(line.strip())\n",
    "            \n",
    "            if \"score\" in record and record[\"score\"] == \"1\"\\\n",
    "                    and \"question-id\" in record and \"answer\" in record:\n",
    "                qa = QA(record[\"question-id\"], None, record[\"answer\"])\n",
    "                qa_dict[record[\"question-id\"]] = qa\n",
    "    return qa_dict\n",
    "\n",
    "def match_questions_to_answers(filepath, qa_dict):\n",
    "    q_wo_a = []\n",
    "    with open(filepath, \"r\") as file:\n",
    "        for line in file:\n",
    "            record = json.loads(line.strip())\n",
    "            \n",
    "            if \"text\" in record and \"_id\" in record:\n",
    "                if record[\"_id\"] in qa_dict.keys():\n",
    "                    qa = qa_dict[record[\"_id\"]]\n",
    "                    qa.question = record[\"text\"]\n",
    "                else:\n",
    "                    qa_dict[NO_ANS].append(record[\"text\"])\n",
    "\n",
    "\n",
    "def organize_question_to_context_relations(filepath, qa_dict):\n",
    "    qc_dict = {}\n",
    "    with open(filepath, \"r\") as file:\n",
    "        for line in file:\n",
    "            record = json.loads(line.strip())\n",
    "            \n",
    "            if \"score\" in record and record[\"score\"] == \"1\"\\\n",
    "                    and \"passage-id\" in record\\\n",
    "                    and \"question-id\" in record and record[\"question-id\"] in qa_dict.keys():\n",
    "                if record[\"passage-id\"] not in qc_dict.keys():\n",
    "                    qc_dict[record[\"passage-id\"]] = []\n",
    "                qc_dict[record[\"passage-id\"]].append(record[\"question-id\"])\n",
    "    return qc_dict\n",
    "\n",
    "def load_passages(filepath, qc_dict, qa_dict):\n",
    "    entries = []\n",
    "    with open(filepath, \"r\") as file:\n",
    "        for line in file:\n",
    "            record = json.loads(line.strip())\n",
    "            \n",
    "            if \"text\" in record and \"_id\" in record and record[\"_id\"] in qc_dict.keys():\n",
    "                qa_ids = qc_dict[record[\"_id\"]]\n",
    "                qas = []\n",
    "                for qa_id in qa_ids:\n",
    "                    qas.append(qa_dict[qa_id])\n",
    "                entries.append(Entry(record[\"_id\"], record[\"text\"], qas))\n",
    "    return entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po uruchomieniu tych fynkcji i przekazaniu odpowiednich plików wejściowych otrzymujemy następujące struktury:\n",
    "`qa_dict` - słownik łączący pytania z odpowiedziami\n",
    "`qc_dict` - słownik łączący pytania z kontekstem\n",
    "`test_passages` - lista z kontekstem oraz połączonymi z nim pytaniami i odpowiedziami\n",
    "\n",
    "Tak przygotowanych struktur będą wykorzystywać, aby zewaluować jakość modelu dla danych testowych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_dict = init_qas_with_answers(\"simple-legal-questions-pl-main/answers.jl\")\n",
    "\n",
    "qa_dict[NO_ANS] = []\n",
    "match_questions_to_answers(\"simple-legal-questions-pl-main/questions.jl\", qa_dict)\n",
    "\n",
    "qc_dict = organize_question_to_context_relations(\"simple-legal-questions-pl-main/relevant.jl\", qa_dict)\n",
    "test_passages = load_passages(\"simple-legal-questions-pl-main/passages.jl\", qc_dict, qa_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dodatkowo napisałem funkcję przekształcającą dane zbioru PoQuAD do reprezentacji odpowiadającej danym testowym. Napisałem ją, gdyż chciałbym dodatkowo policzyć metryki dla zbioru walidacyjnego dokładnie tymi samymi funkcjami, co dla zbioru testowego."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_poquad_data(filepath):\n",
    "    val_entries = []\n",
    "    with open(filepath, \"r\") as file:\n",
    "        json_content = json.load(file)\n",
    "        for data in json_content['data']:\n",
    "            for paragraph in data['paragraphs']:\n",
    "                qa_list = []\n",
    "                for qa in paragraph['qas']:\n",
    "                    answers = qa['answers'] if 'answers' in qa.keys() else qa['plausible_answers']\n",
    "                    for answer in answers:\n",
    "                        qa_obj = QA(None, qa['question'], answer['generative_answer'])\n",
    "                        qa_list.append(qa_obj)\n",
    "                    \n",
    "                entry = Entry(None, paragraph['context'], qa_list)\n",
    "                val_entries.append(entry)\n",
    "    return val_entries\n",
    "\n",
    "val_passages = convert_poquad_data(\"poquad-dev.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funkcja `exec_passages` przechodzi po kontekstach w podanym zbiorze i przekazuje je do modelu wraz z pytaniami i odpowiedziami na nie. Wyjściowo otrzymujemy listę odpowiedzi modelu oraz oczekiwanych odpowiedzi generatywnych."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def exec_passages(model, tokenizer, passages):\n",
    "    answers = []\n",
    "    expected_answers = []\n",
    "    for passage in tqdm(passages):\n",
    "        for qa in passage.qas:\n",
    "            input_text = f\"question: {qa.question} context: {passage.passage_text}\"\n",
    "            inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "            outputs = model.generate(inputs[\"input_ids\"], max_length=100, num_beams=5, early_stopping=True)\n",
    "\n",
    "            answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            answers.append(answer)\n",
    "            expected_answers.append(qa.answer)\n",
    "    return answers, expected_answers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Teraz wystarczy wczytać odpowiedni model i wyznaczyć jego odpowiedzi na pytania ze zbioru poprzez wywolanie powyższej funkcji:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [16:48<00:00,  1.81s/it]\n"
     ]
    }
   ],
   "source": [
    "answers, expected_answers = exec_passages(ready_model, ready_model_tokenizer, test_passages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 55/1453 [04:46<2:01:27,  5.21s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m val_answers, expected_answers \u001b[38;5;241m=\u001b[39m \u001b[43mexec_passages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mready_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mready_model_tokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_passages\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 11\u001b[0m, in \u001b[0;36mexec_passages\u001b[0;34m(model, tokenizer, passages)\u001b[0m\n\u001b[1;32m      8\u001b[0m input_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mqa\u001b[38;5;241m.\u001b[39mquestion\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m context: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassage\u001b[38;5;241m.\u001b[39mpassage_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      9\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(input_text, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 11\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_beams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m answer \u001b[38;5;241m=\u001b[39m tokenizer\u001b[38;5;241m.\u001b[39mdecode(outputs[\u001b[38;5;241m0\u001b[39m], skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     14\u001b[0m answers\u001b[38;5;241m.\u001b[39mappend(answer)\n",
      "File \u001b[0;32m~/Documents/ds/_semestr_9/przetwarzanie_jezyka_naturalnego/labs/.venv/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ds/_semestr_9/przetwarzanie_jezyka_naturalnego/labs/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:2285\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2277\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   2278\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   2279\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[1;32m   2280\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   2281\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   2282\u001b[0m     )\n\u001b[1;32m   2284\u001b[0m     \u001b[38;5;66;03m# 13. run beam sample\u001b[39;00m\n\u001b[0;32m-> 2285\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_beam_search\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2286\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2287\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeam_scorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2288\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2290\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2291\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2292\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2293\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2295\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;241m==\u001b[39m GenerationMode\u001b[38;5;241m.\u001b[39mGROUP_BEAM_SEARCH:\n\u001b[1;32m   2296\u001b[0m     \u001b[38;5;66;03m# 11. prepare beam search scorer\u001b[39;00m\n\u001b[1;32m   2297\u001b[0m     beam_scorer \u001b[38;5;241m=\u001b[39m BeamSearchScorer(\n\u001b[1;32m   2298\u001b[0m         batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   2299\u001b[0m         num_beams\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_beams,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2305\u001b[0m         max_length\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mmax_length,\n\u001b[1;32m   2306\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/ds/_semestr_9/przetwarzanie_jezyka_naturalnego/labs/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:3597\u001b[0m, in \u001b[0;36mGenerationMixin._beam_search\u001b[0;34m(self, input_ids, beam_scorer, logits_processor, stopping_criteria, generation_config, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   3594\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m outputs\n\u001b[1;32m   3596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model_kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 3597\u001b[0m     model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpast_key_values\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_temporary_reorder_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpast_key_values\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbeam_idx\u001b[49m\n\u001b[1;32m   3599\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3601\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_dict_in_generate \u001b[38;5;129;01mand\u001b[39;00m output_scores:\n\u001b[1;32m   3602\u001b[0m     beam_indices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m((beam_indices[beam_idx[i]] \u001b[38;5;241m+\u001b[39m (beam_idx[i],) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(beam_indices))))\n",
      "File \u001b[0;32m~/Documents/ds/_semestr_9/przetwarzanie_jezyka_naturalnego/labs/.venv/lib/python3.12/site-packages/transformers/generation/utils.py:3371\u001b[0m, in \u001b[0;36mGenerationMixin._temporary_reorder_cache\u001b[0;34m(self, past_key_values, beam_idx)\u001b[0m\n\u001b[1;32m   3368\u001b[0m     past_key_values \u001b[38;5;241m=\u001b[39m DynamicCache\u001b[38;5;241m.\u001b[39mfrom_legacy_cache(past_key_values)\n\u001b[1;32m   3369\u001b[0m \u001b[38;5;66;03m# Standard code path: use the `Cache.reorder_cache`\u001b[39;00m\n\u001b[1;32m   3370\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3371\u001b[0m     \u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreorder_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeam_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3372\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m past_key_values\n",
      "File \u001b[0;32m~/Documents/ds/_semestr_9/przetwarzanie_jezyka_naturalnego/labs/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:1494\u001b[0m, in \u001b[0;36mEncoderDecoderCache.reorder_cache\u001b[0;34m(self, beam_idx)\u001b[0m\n\u001b[1;32m   1492\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreorder_cache\u001b[39m(\u001b[38;5;28mself\u001b[39m, beam_idx: torch\u001b[38;5;241m.\u001b[39mLongTensor):\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Reorders the cache for beam search, given the selected beam indices.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1494\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attention_cache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreorder_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeam_idx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1495\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attention_cache\u001b[38;5;241m.\u001b[39mreorder_cache(beam_idx)\n",
      "File \u001b[0;32m~/Documents/ds/_semestr_9/przetwarzanie_jezyka_naturalnego/labs/.venv/lib/python3.12/site-packages/transformers/cache_utils.py:100\u001b[0m, in \u001b[0;36mCache.reorder_cache\u001b[0;34m(self, beam_idx)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_cache[layer_idx] \u001b[38;5;241m!=\u001b[39m []:\n\u001b[1;32m     99\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_cache[layer_idx]\u001b[38;5;241m.\u001b[39mdevice\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_cache[layer_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalue_cache[layer_idx]\u001b[38;5;241m.\u001b[39mindex_select(\u001b[38;5;241m0\u001b[39m, \u001b[43mbeam_idx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "val_answers, val_expected_answers = exec_passages(ready_model, ready_model_tokenizer, val_passages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "my_t5_base_model_name = \"./model_poquad_abstr\"\n",
    "my_t5_base_model_tokenizer = AutoTokenizer.from_pretrained(my_t5_base_model_name)\n",
    "my_t5_base_model = AutoModelForSeq2SeqLM.from_pretrained(my_t5_base_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [11:03<00:00,  1.19s/it]\n"
     ]
    }
   ],
   "source": [
    "my_answers, expected_answers = exec_passages(my_t5_base_model, my_t5_base_model_tokenizer, test_passages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1453/1453 [2:33:27<00:00,  6.34s/it]  \n"
     ]
    }
   ],
   "source": [
    "my_val_answers, val_expected_answers = exec_passages(my_t5_base_model, my_t5_base_model_tokenizer, val_passages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "lr2e_5_b16_t5_base_model_name = \"./model_poquad_t5_base_2e-5_b16\"\n",
    "lr2e_5_b16_t5_base_model_tokenizer = AutoTokenizer.from_pretrained(lr2e_5_b16_t5_base_model_name)\n",
    "lr2e_5_b16_t5_base_model = AutoModelForSeq2SeqLM.from_pretrained(lr2e_5_b16_t5_base_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [13:39<00:00,  1.47s/it]\n"
     ]
    }
   ],
   "source": [
    "lr2e_5_b16_t5_base_answers, expected_answers = exec_passages(lr2e_5_b16_t5_base_model, lr2e_5_b16_t5_base_model_tokenizer, test_passages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "lr4e_5_b16_t5_base_model_name = \"./model_poquad_t5_base_f1_4e-5_b16\"\n",
    "lr4e_5_b16_t5_base_model_tokenizer = AutoTokenizer.from_pretrained(lr4e_5_b16_t5_base_model_name)\n",
    "lr4e_5_b16_t5_base_model = AutoModelForSeq2SeqLM.from_pretrained(lr4e_5_b16_t5_base_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [16:26<00:00,  1.77s/it]\n"
     ]
    }
   ],
   "source": [
    "lr4e_5_b16_t5_base_answers, expected_answers = exec_passages(lr4e_5_b16_t5_base_model, lr4e_5_b16_t5_base_model_tokenizer, test_passages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "lr2e_5_b8_t5_base_model_name = \"./model_poquad_t5_base_f1_2e-5_b8\"\n",
    "lr2e_5_b8_t5_base_model_tokenizer = AutoTokenizer.from_pretrained(lr2e_5_b8_t5_base_model_name)\n",
    "lr2e_5_b8_t5_base_model = AutoModelForSeq2SeqLM.from_pretrained(lr2e_5_b8_t5_base_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2e_5_b8_t5_base_answers, expected_answers = exec_passages(lr2e_5_b8_t5_base_model, lr2e_5_b8_t5_base_model_tokenizer, test_passages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "lr5e_5_b16_t5_base_model_name = \"./model_poquad_t5_base_f1_5e-5_b16\"\n",
    "lr5e_5_b16_t5_base_model_tokenizer = AutoTokenizer.from_pretrained(lr5e_5_b16_t5_base_model_name)\n",
    "lr5e_5_b16_t5_base_model = AutoModelForSeq2SeqLM.from_pretrained(lr5e_5_b16_t5_base_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [14:17<00:00,  1.54s/it]\n"
     ]
    }
   ],
   "source": [
    "lr5e_5_b16_t5_base_answers, expected_answers = exec_passages(lr5e_5_b16_t5_base_model, lr5e_5_b16_t5_base_model_tokenizer, test_passages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "lr3e_5_b12_t5_base_model_name = \"./model_poquad_t5_base_f1_3e-5_b12\"\n",
    "lr3e_5_b12_t5_base_model_tokenizer = AutoTokenizer.from_pretrained(lr3e_5_b12_t5_base_model_name)\n",
    "lr3e_5_b12_t5_base_model = AutoModelForSeq2SeqLM.from_pretrained(lr3e_5_b12_t5_base_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 557/557 [13:42<00:00,  1.48s/it]\n"
     ]
    }
   ],
   "source": [
    "lr3e_5_b12_t5_base_answers, expected_answers = exec_passages(lr3e_5_b12_t5_base_model, lr3e_5_b12_t5_base_model_tokenizer, test_passages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniżej znajduje się funkcja odnajdująca dokładne dopasowanie (*Exact Match*). Zawiera ona mały etap wstępnego przetworzenia tekstów na wejściu, który to usuwa skrajne spacje, znaki interpunkcyjne i zmniejsza czcionkę wszystkich słów, tak żeby lepiej odkrywać dokładne dopasowania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def clean_text(s):\n",
    "    s = s.strip()\n",
    "    s = s.lower()\n",
    "    s = ''.join(c for c in s if c not in string.punctuation)\n",
    "    return s\n",
    "\n",
    "\n",
    "def calculate_exact_matches(answers, expected_answers, clean_fun):\n",
    "    matches = 0\n",
    "    for s1, s2 in zip(answers, expected_answers):\n",
    "        if clean_fun(s1) == clean_fun(s2):\n",
    "            matches += 1\n",
    "    return matches/len(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2456445993031359"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_exact_matches(my_answers, expected_answers, clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2264808362369338"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_exact_matches(lr2e_5_b16_t5_base_answers, expected_answers, clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24390243902439024"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_exact_matches(lr4e_5_b16_t5_base_answers, expected_answers, clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2456445993031359"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_exact_matches(answers, expected_answers, clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.24738675958188153"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_exact_matches(lr5e_5_b16_t5_base_answers, expected_answers, clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2874564459930314"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_exact_matches(lr3e_5_b12_t5_base_answers, expected_answers, clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ostatecznie funkcja mierząca wartości TP, FP, FN i wyznaczająca na ich podstawie metryki `precision` i `recall` aby zwrócić opierającą się o nie metrykę `f1`. Poza dwoma odpowiedziami funkcja przyjmuje funkcję tokenizującą, która przeprowadza czyszczenie tekstu takie samo, jak w przypadku *Exact Match*, i dodatkowo tworzy tokeny z już dalej nieprzetworzonych słów zdania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "def tokenize(text):\n",
    "    text = clean_text(text)\n",
    "    tokens = re.split(r\"[^\\w]+\", text)\n",
    "    return tokens\n",
    "\n",
    "def compute_single_f1(tokens1, tokens2):\n",
    "    TP = sum((tokens1 & tokens2).values())\n",
    "    FP = sum((tokens1 - tokens2).values())\n",
    "    FN = sum((tokens2 - tokens1).values())\n",
    "\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    return f1\n",
    "\n",
    "def compute_f1(answers, expected_answers, tokenize_fun):\n",
    "\n",
    "    f1_scores = []\n",
    "    for s1, s2 in zip(answers, expected_answers):\n",
    "        s1_t = Counter(tokenize_fun(s1))\n",
    "        s2_t = Counter(tokenize_fun(s2))\n",
    "        f1 = compute_single_f1(s1_t, s2_t)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "    return sum(f1_scores)/len(f1_scores)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5184004475490456"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_f1(answers, expected_answers, tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5120417923766273"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_f1(my_answers, expected_answers, tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5053607657978532"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_f1(lr2e_5_b16_t5_base_answers, expected_answers, tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5172354390737379"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_f1(lr4e_5_b16_t5_base_answers, expected_answers, tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5125987055942087"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_f1(lr5e_5_b16_t5_base_answers, expected_answers, tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5257402393193848"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_f1(lr3e_5_b12_t5_base_answers, expected_answers, tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7216107340920863"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_f1(my_val_answers, val_expected_answers, tokenize)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Żeby sprawdzić, czy fleksja ma duże znaczenie przy obliczaniu metryki `f1`, stworzę dodatkową funkcję, która poza wyodrębnieniem poszczególnych słów w odpowidzi, dodatkowo zlematyzuje te słowa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pl-core-news-lg==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/pl_core_news_lg-3.8.0/pl_core_news_lg-3.8.0-py3-none-any.whl (573.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m573.7/573.7 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:05\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pl-core-news-lg\n",
      "Successfully installed pl-core-news-lg-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('pl_core_news_lg')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download pl_core_news_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"pl_core_news_lg\")\n",
    "\n",
    "def tokenize_and_lemmatize(text):\n",
    "    tokens = tokenize(text)\n",
    "    text = \" \".join(tokens)\n",
    "\n",
    "    doc = nlp(text)\n",
    "    lemmatized_tokens = [token.lemma_ for token in doc]\n",
    "    return lemmatized_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5395675134388546"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_f1(lr3e_5_b12_t5_base_answers, expected_answers, tokenize_and_lemmatize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okazuje się, że dodatkowa lematyzacja słów dla `f1` tylko nieznacznie poprawia wynik, co jest dla mnie poniekąd zaskoczeniem.\n",
    "\n",
    "Mimo wszystko języki z bogatą fleksją już na poziomie przygotowywania modelu wpływają na jego działanie. Mianowicie model ten musi uwzględnić fleksję zarówno przy tokenizacji, jak i przy budowaniu osadzeń dla wczytanych tokenów. Fleksja prowadzi najpewniej do zwiększenia liczby unikalnych tokenów obsługiwanych przez model, oraz musi zostać uwzględniona w budowie kontekstu dla poszczególnych tokenów, przez co potrzebujemy pojemniejszego modelu i większej liczby zdań w korpusie uczącym, aby dobrze odwzorować zachodzące zależności fleksyjne.\n",
    "\n",
    "Takie dodatkowe wymagania wobec modelu utrudniają jego działanie i przyczyniają się do pogorszenia jakości wyników względem porównywalnego zbioru danych w języku o uboższej fleksji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def store_answers_in_json(answers, file_path):\n",
    "    with open(file_path, \"w\") as f:\n",
    "        json.dump(answers, f)\n",
    "\n",
    "def load_answers_from_json(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        return json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_answers_in_json(lr3e_5_b12_t5_base_answers, \"lr3e_5_b12_t5_base_answers.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
