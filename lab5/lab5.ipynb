{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marcin Wardyński  \n",
    "czwartek, 8:00\n",
    "\n",
    "### Laboratorium 5: Klasyfikacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lab5_utils as utils\n",
    "\n",
    "corpus, queries, qrels = utils.load_fiqa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO check the intersection between test, validation and test. Reconsider sizes of the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "pl_tokenizer = AutoTokenizer.from_pretrained(\"allegro/herbert-base-cased\")\n",
    "separator = pl_tokenizer.sep_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vate_query_to_corpus_dict = utils.prepare_fiqa_qrels(qrels, ['validation', 'test'])\n",
    "no_vate_corpus_dict = utils.prepare_fiqa_corpus_related_to_selected_subsets(corpus, vate_query_to_corpus_dict, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to delete index 'mw_nlp_lab5_train': {\"error\":{\"root_cause\":[{\"type\":\"index_not_found_exception\",\"reason\":\"no such index [mw_nlp_lab5_train]\",\"resource.type\":\"index_or_alias\",\"resource.id\":\"mw_nlp_lab5_train\",\"index_uuid\":\"_na_\",\"index\":\"mw_nlp_lab5_train\"}],\"type\":\"index_not_found_exception\",\"reason\":\"no such index [mw_nlp_lab5_train]\",\"resource.type\":\"index_or_alias\",\"resource.id\":\"mw_nlp_lab5_train\",\"index_uuid\":\"_na_\",\"index\":\"mw_nlp_lab5_train\"},\"status\":404}\n",
      "Index created.\n",
      "All documents indexed successfully.\n"
     ]
    }
   ],
   "source": [
    "train_index_name = \"mw_nlp_lab5_train\"\n",
    "fts_url, train_index_url = utils.create_fts_index(train_index_name)\n",
    "utils.bulk_load(fts_url, train_index_name, no_vate_corpus_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to delete index 'mw_nlp_lab5_validation': {\"error\":{\"root_cause\":[{\"type\":\"index_not_found_exception\",\"reason\":\"no such index [mw_nlp_lab5_validation]\",\"resource.type\":\"index_or_alias\",\"resource.id\":\"mw_nlp_lab5_validation\",\"index_uuid\":\"_na_\",\"index\":\"mw_nlp_lab5_validation\"}],\"type\":\"index_not_found_exception\",\"reason\":\"no such index [mw_nlp_lab5_validation]\",\"resource.type\":\"index_or_alias\",\"resource.id\":\"mw_nlp_lab5_validation\",\"index_uuid\":\"_na_\",\"index\":\"mw_nlp_lab5_validation\"},\"status\":404}\n",
      "Index created.\n",
      "All documents indexed successfully.\n"
     ]
    }
   ],
   "source": [
    "va_query_to_corpus_dict = utils.prepare_fiqa_qrels(qrels, ['validation'])\n",
    "va_corpus_dict = utils.prepare_fiqa_corpus_related_to_selected_subsets(corpus, va_query_to_corpus_dict, True)\n",
    "\n",
    "validation_index_name = \"mw_nlp_lab5_validation\"\n",
    "fts_url, validation_index_url = utils.create_fts_index(validation_index_name)\n",
    "utils.bulk_load(fts_url, validation_index_name, va_corpus_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def collect_training_dataset(index_url, corpus_dict, subsets, separator):\n",
    "    query_to_corpus_dict = utils.prepare_fiqa_qrels(qrels, subsets)\n",
    "    queries_dict = utils.prepare_fiqa_queries_for_selected_subset(queries, query_to_corpus_dict)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for q_id, q_text in queries_dict.items():\n",
    "        collect_passages_for_query(q_id, q_text, corpus_dict, query_to_corpus_dict, index_url, results, separator)\n",
    "\n",
    "    return Dataset.from_list(results)\n",
    "\n",
    "def collect_passages_for_query(q_id, q_text, p_dict, q_to_p_dict, index_url, results, separator):\n",
    "    q_p_ids = list(q_to_p_dict[q_id].keys())\n",
    "\n",
    "    for q_p_id in q_p_ids:\n",
    "        results.append(convert_to_json(q_text, p_dict[q_p_id], 1, separator))\n",
    "        \n",
    "    fts_results = utils.find_for_phrase_with_exclusion(index_url, q_text, 'text', 3*len(q_p_ids), q_p_ids)\n",
    "    for fts_result_id in fts_results:\n",
    "        results.append(convert_to_json(q_text, p_dict[fts_result_id], 0, separator))\n",
    "\n",
    "def convert_to_json(q_text, p_text, label, separator):\n",
    "    return {\n",
    "            \"text\": f\"{q_text}{separator}{p_text}\",\n",
    "            \"label\": label,\n",
    "        }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = collect_training_dataset(train_index_url, no_vate_corpus_dict, ['train'], separator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = collect_training_dataset(validation_index_url, va_corpus_dict, ['validation'], separator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 56664/56664 [00:00<00:00, 615611.47 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 4952/4952 [00:00<00:00, 483961.91 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "datasets = DatasetDict({\"train\": train_dataset, \"validation\": validation_dataset})\n",
    "datasets.save_to_disk(\"./question-passage-classification\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przygotowanie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 56664/56664 [00:11<00:00, 4814.01 examples/s]\n",
      "Map: 100%|██████████| 4952/4952 [00:01<00:00, 4339.01 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 56664\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return pl_tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = datasets.map(tokenize_function, batched=True)\n",
    "tokenized_datasets[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Co jest uważane za wydatek służbowy w podróży służbowej?</s>Wytyczne IRS dotyczące tematu. Ogólnie rzecz biorąc, najlepsze, co mogę powiedzieć, to to, że Twój wydatek biznesowy może podlegać odliczeniu. Ale to zależy od okoliczności i tego, co chcesz odliczyć. Podróże Podatnicy, którzy wyjeżdżają z domu w celach służbowych, mogą odliczyć związane z tym wydatki, w tym koszty dotarcia do miejsca docelowego, koszty zakwaterowania i wyżywienia oraz inne zwykłe i niezbędne wydatki. Podatnicy są uważani za „wyjeżdżających poza dom”, jeśli ich obowiązki wymagają od nich przebywania poza domem znacznie dłużej niż zwykły dzień pracy i muszą spać lub odpoczywać, aby sprostać wymogom pracy. Można odliczyć rzeczywisty koszt posiłków i nieprzewidziane wydatki lub skorzystać ze standardowej diety żywieniowej i obniżonych wymogów ewidencji. Niezależnie od zastosowanej metody odliczenia posiłków są zazwyczaj ograniczone do 50 procent, jak wspomniano wcześniej. Jako koszt można zgłaszać tylko rzeczywiste koszty zakwaterowania, a rachunki należy przechowywać do dokumentacji. Wydatki muszą być rozsądne i odpowiednie; potrącenia z tytułu nadmiernych wydatków nie są dopuszczalne. Więcej informacji można znaleźć w publikacji 463, Podróże, rozrywka, prezenty i wydatki na samochód. Rozrywka Wydatki na rozrywkę dla klientów, klientów lub pracowników mogą być odliczane, jeśli są one zarówno zwyczajne, jak i konieczne oraz spełniają jeden z następujących testów: Test bezpośrednio związany: Głównym celem działalności rozrywkowej jest prowadzenie działalności, działalność była faktycznie prowadzona podczas działalność i podatnik mieli więcej niż ogólne oczekiwanie uzyskania dochodu lub innej konkretnej korzyści biznesowej w przyszłości. Powiązany test: rozrywka była związana z aktywnym prowadzeniem działalności handlowej lub biznesowej podatnika i miała miejsce bezpośrednio przed lub po istotnej dyskusji biznesowej. Publikacja 463 zawiera obszerniejsze wyjaśnienie tych testów, jak również innych ograniczeń i wymagań dotyczących odliczania wydatków na rozrywkę. Prezenty Podatnicy mogą odliczyć część lub całość kosztów prezentów wręczanych w ramach ich działalności handlowej lub biznesowej. Ogólnie rzecz biorąc, odliczenie jest ograniczone do 25 USD za prezenty wręczane bezpośrednio lub pośrednio jednej osobie w ciągu roku podatkowego. Więcej omówienia zasad i ograniczeń można znaleźć w Publikacji 463. Jeśli Twoja spółka LLC zwróci Ci wydatki wykraczające poza te wytyczne, należy je traktować jako dochód dla celów podatkowych. Edytuj koszty posiłków: Kwota standardowego dodatku na posiłki. Standardowy dodatek na posiłki to federalna stawka M&IE. W przypadku podróży w 2010 r. stawka dla większości małych miejscowości w Stanach Zjednoczonych wynosi 46 USD dziennie. Źródło IRS P463 Alternatywnie możesz dokonać zwrotu według stawki dziennej\n",
      "[0, 3407, 2092, 39104, 2163, 23004, 11418, 2348, 1019, 10273, 45454, 1550, 2, 2331, 4603, 45, 19295, 5666, 16094, 1899, 38126, 4662, 13786, 1947, 9104, 1947, 2249, 5492, 4041, 1947, 2063, 2063, 1947, 2040, 22761, 23004, 6596, 11088, 2402, 36663, 21386, 4068, 1899, 2894, 2063, 6466, 2173, 11056, 1009, 2210, 1947, 2249, 13792, 43844, 1899, 2579, 19886, 38900, 2510, 1947, 2634, 28991, 1046, 3537, 1019, 24173, 25502, 1947, 3065, 43844, 5307, 1046, 2194, 10166, 1947, 1019, 2194, 6159, 7578, 2333, 2041, 3845, 33663, 2512, 1947, 6159, 26226, 9578, 1009, 20440, 4397, 2248, 3914, 22717, 1009, 11434, 10166, 1899, 38900, 2510, 2264, 3329, 2572, 2163, 1791, 10138, 3862, 4445, 5157, 1956, 1947, 3346, 2186, 11137, 13899, 2173, 2531, 45946, 4445, 16713, 4432, 7847, 2876, 17533, 3501, 2631, 1009, 4730, 17088, 2491, 14714, 2726, 1947, 2802, 29335, 15040, 14229, 2631, 1899, 5354, 43844, 48244, 8890, 28069, 1009, 2013, 21070, 10166, 2491, 8981, 2343, 6740, 11577, 21308, 30022, 6910, 1009, 9997, 2589, 17834, 20116, 1899, 23897, 2173, 6171, 4695, 11244, 21386, 2700, 28069, 2264, 10307, 22454, 2041, 2693, 5195, 1947, 2217, 7640, 2890, 3695, 1899, 6843, 8890, 2545, 16451, 2308, 36870, 6159, 26226, 9578, 1947, 1011, 18567, 3406, 13465, 2726, 2041, 14348, 1899, 44001, 4730, 2458, 14482, 2079, 1009, 10161, 1195, 17877, 4081, 1046, 6234, 12631, 2089, 9752, 1997, 2264, 34310, 1899, 10249, 4338, 2545, 5378, 1019, 14020, 24, 5783, 1947, 2579, 19886, 1947, 11932, 6958, 1947, 24274, 1009, 10166, 1998, 6704, 1899, 44942, 6958, 44001, 1998, 11932, 14335, 2211, 7128, 1947, 7128, 2491, 4424, 3065, 2458, 2021, 2519, 2414, 1947, 3346, 2264, 2290, 4635, 10073, 2079, 1947, 2217, 1009, 10375, 2248, 23352, 3247, 1046, 22358, 26641, 1335, 39309, 7616, 10743, 1335, 11692, 7432, 4654, 19695, 4137, 2092, 4649, 4654, 1947, 5142, 2663, 11782, 11786, 3095, 5142, 1009, 39055, 4153, 2944, 2876, 18991, 18687, 10521, 16776, 2491, 8049, 24278, 10948, 6596, 8906, 1019, 6174, 1899, 52, 2945, 2003, 2067, 14825, 1335, 11932, 6958, 2663, 13413, 1046, 43885, 16481, 4654, 25243, 2491, 6596, 8906, 29951, 1009, 3943, 2963, 7616, 2534, 2491, 2184, 4666, 2130, 6204, 6596, 8906, 1899, 6787, 20292, 24, 5783, 9138, 15150, 3955, 18880, 2513, 26641, 1947, 2217, 2604, 3112, 18609, 1009, 20702, 7371, 21386, 6819, 9752, 1998, 11932, 14335, 1899, 16244, 2162, 38900, 2510, 3065, 43844, 3865, 2491, 13680, 6510, 38641, 5004, 1988, 2826, 1019, 4300, 2186, 4654, 25243, 2491, 6596, 8906, 1899, 38126, 4662, 13786, 1947, 21386, 2824, 2092, 22454, 2041, 2698, 20123, 2163, 24274, 5004, 39803, 7616, 2491, 24424, 4192, 14507, 1019, 3747, 2254, 23934, 1899, 10249, 83, 17304, 8045, 1009, 18609, 2545, 5378, 1019, 6787, 4712, 24, 5783, 1899, 3484, 13462, 10160, 48, 48, 1023, 32547, 7086, 10166, 23787, 43725, 4445, 2322, 48866, 1947, 3406, 2193, 16217, 2628, 13131, 2211, 10664, 15415, 1899, 12828, 41956, 6159, 28069, 1335, 33892, 6740, 13975, 10276, 1998, 25520, 1899, 27336, 10962, 11080, 1998, 25520, 2063, 11098, 18957, 20941, 1058, 1664, 12065, 1899, 1049, 3714, 10273, 1019, 9441, 1024, 1899, 20941, 2211, 6043, 7918, 6020, 1019, 13531, 9034, 5979, 3523, 20123, 9216, 1899, 23301, 45, 19295, 52, 24, 5783, 34465, 17643, 11814, 12241, 13452, 2]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "<s>|Co</w>|jest</w>|uważane</w>|za</w>|wydatek</w>|służb|owy</w>|w</w>|podróży</w>|służbowej</w>|?</w>|</s>|Wy|tyczne</w>|I|RS</w>|dotyczące</w>|tematu</w>|.</w>|Ogólnie</w>|rzecz</w>|biorąc</w>|,</w>|najlepsze</w>|,</w>|co</w>|mogę</w>|powiedzieć</w>|,</w>|to</w>|to</w>|,</w>|że</w>|Twój</w>|wydatek</w>|bizne|sowy</w>|może</w>|podlegać</w>|odli|czeniu</w>|.</w>|Ale</w>|to</w>|zależy</w>|od</w>|okoliczności</w>|i</w>|tego</w>|,</w>|co</w>|chcesz</w>|odliczyć</w>|.</w>|Pod|róże</w>|Podat|nicy</w>|,</w>|którzy</w>|wyjeżdżają</w>|z</w>|domu</w>|w</w>|celach</w>|służbowych</w>|,</w>|mogą</w>|odliczyć</w>|związane</w>|z</w>|tym</w>|wydatki</w>|,</w>|w</w>|tym</w>|koszty</w>|dotar|cia</w>|do</w>|miejsca</w>|docel|owego</w>|,</w>|koszty</w>|zakwate|rowania</w>|i</w>|wyży|wienia</w>|oraz</w>|inne</w>|zwykłe</w>|i</w>|niezbędne</w>|wydatki</w>|.</w>|Podat|nicy</w>|są</w>|uważ|ani</w>|za</w>|„</w>|wyjeżdż|ających</w>|poza</w>|dom</w>|”</w>|,</w>|jeśli</w>|ich</w>|obowiązki</w>|wymagają</w>|od</w>|nich</w>|przebywania</w>|poza</w>|domem</w>|znacznie</w>|dłużej</w>|niż</w>|zwykły</w>|dzień</w>|pracy</w>|i</w>|muszą</w>|spać</w>|lub</w>|odpoczy|wać</w>|,</w>|aby</w>|sprostać</w>|wymo|gom</w>|pracy</w>|.</w>|Można</w>|odliczyć</w>|rzeczywisty</w>|koszt</w>|posiłków</w>|i</w>|nie|przewidziane</w>|wydatki</w>|lub</w>|skorzystać</w>|ze</w>|standar|dowej</w>|diety</w>|żywie|niowej</w>|i</w>|obniż|onych</w>|wymogów</w>|ewidencji</w>|.</w>|Niezależnie</w>|od</w>|zastos|owanej</w>|metody</w>|odli|czenia</w>|posiłków</w>|są</w>|zazwyczaj</w>|ograniczone</w>|do</w>|50</w>|procent</w>|,</w>|jak</w>|wspomni|ano</w>|wcześniej</w>|.</w>|Jako</w>|koszt</w>|można</w>|zgłaszać</w>|tylko</w>|rzeczywiste</w>|koszty</w>|zakwate|rowania</w>|,</w>|a</w>|rachunki</w>|należy</w>|przechowy|wać</w>|do</w>|dokumentacji</w>|.</w>|Wydatki</w>|muszą</w>|być</w>|rozsąd|ne</w>|i</w>|odpowiednie</w>|;</w>|potrą|cenia</w>|z</w>|tytułu</w>|nadmier|nych</w>|wydatków</w>|nie</w>|są</w>|dopuszczalne</w>|.</w>|Więcej</w>|informacji</w>|można</w>|znaleźć</w>|w</w>|publikacji</w>|4|63</w>|,</w>|Pod|róże</w>|,</w>|rozry|wka</w>|,</w>|prezenty</w>|i</w>|wydatki</w>|na</w>|samochód</w>|.</w>|Rozry|wka</w>|Wydatki</w>|na</w>|rozry|wkę</w>|dla</w>|klientów</w>|,</w>|klientów</w>|lub</w>|pracowników</w>|mogą</w>|być</w>|od|licz|ane</w>|,</w>|jeśli</w>|są</w>|one</w>|zarówno</w>|zwyczaj|ne</w>|,</w>|jak</w>|i</w>|konieczne</w>|oraz</w>|spełniają</w>|jeden</w>|z</w>|następujących</w>|testów</w>|:</w>|Test</w>|bezpośrednio</w>|związany</w>|:</w>|Głównym</w>|celem</w>|działalności</w>|rozryw|kowej</w>|jest</w>|prowadzenie</w>|działalności</w>|,</w>|działalność</w>|była</w>|faktycznie</w>|prowadzona</w>|podczas</w>|działalność</w>|i</w>|podatnik</w>|mieli</w>|więcej</w>|niż</w>|ogólne</w>|oczekiwanie</w>|uzyskania</w>|dochodu</w>|lub</w>|innej</w>|konkretnej</w>|korzyści</w>|bizne|sowej</w>|w</w>|przyszłości</w>|.</w>|P|owią|za|ny</w>|test</w>|:</w>|rozry|wka</w>|była</w>|związana</w>|z</w>|aktywnym</w>|prowadzeniem</w>|działalności</w>|handlowej</w>|lub</w>|bizne|sowej</w>|podatnika</w>|i</w>|miała</w>|miejsce</w>|bezpośrednio</w>|przed</w>|lub</w>|po</w>|istot|nej</w>|dyskusji</w>|bizne|sowej</w>|.</w>|Publi|kacja</w>|4|63</w>|zawiera</w>|obszer|niejsze</w>|wyjaśnienie</w>|tych</w>|testów</w>|,</w>|jak</w>|również</w>|innych</w>|ograniczeń</w>|i</w>|wymagań</w>|dotyczących</w>|odli|czania</w>|wydatków</w>|na</w>|rozry|wkę</w>|.</w>|Prezen|ty</w>|Podat|nicy</w>|mogą</w>|odliczyć</w>|część</w>|lub</w>|całość</w>|kosztów</w>|prezentów</w>|wrę|cz|anych</w>|w</w>|ramach</w>|ich</w>|działalności</w>|handlowej</w>|lub</w>|bizne|sowej</w>|.</w>|Ogólnie</w>|rzecz</w>|biorąc</w>|,</w>|odli|czenie</w>|jest</w>|ograniczone</w>|do</w>|25</w>|USD</w>|za</w>|prezenty</w>|wrę|czane</w>|bezpośrednio</w>|lub</w>|pośrednio</w>|jednej</w>|osobie</w>|w</w>|ciągu</w>|roku</w>|podatkowego</w>|.</w>|Więcej</w>|o|mówienia</w>|zasad</w>|i</w>|ograniczeń</w>|można</w>|znaleźć</w>|w</w>|Publi|kacji</w>|4|63</w>|.</w>|Jeśli</w>|Twoja</w>|spółka</w>|L|L|C</w>|zwróci</w>|Ci</w>|wydatki</w>|wykra|czające</w>|poza</w>|te</w>|wytyczne</w>|,</w>|należy</w>|je</w>|traktować</w>|jako</w>|dochód</w>|dla</w>|celów</w>|podatkowych</w>|.</w>|Edy|tuj</w>|koszty</w>|posiłków</w>|:</w>|Kwota</w>|standar|dowego</w>|dodatku</w>|na</w>|posiłki</w>|.</w>|Standar|dowy</w>|dodatek</w>|na</w>|posiłki</w>|to</w>|fede|ralna</w>|stawka</w>|M</w>|&</w>|IE</w>|.</w>|W</w>|przypadku</w>|podróży</w>|w</w>|2010</w>|r</w>|.</w>|stawka</w>|dla</w>|większości</w>|małych</w>|miejscowości</w>|w</w>|Stanach</w>|Zjednoczonych</w>|wynosi</w>|46</w>|USD</w>|dziennie</w>|.</w>|Źródło</w>|I|RS</w>|P|4|63</w>|Alterna|tywnie</w>|możesz</w>|dokonać</w>|zwrotu</w>|</s>\n",
      "512\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "example = tokenized_datasets[\"train\"][0]\n",
    "print(example[\"text\"])\n",
    "print(example[\"input_ids\"])\n",
    "print(example[\"attention_mask\"])\n",
    "print(\"|\".join(pl_tokenizer.convert_ids_to_tokens(list(example[\"input_ids\"]))))\n",
    "\n",
    "print(len([e for e in example[\"input_ids\"] if e != 1]))\n",
    "print(len([e for e in example[\"attention_mask\"] if e == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allegro/herbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(50000, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"allegro/herbert-base-cased\", num_labels=2\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "arguments = TrainingArguments(\n",
    "    output_dir=\"./output\",\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=300,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=5e-05,\n",
    "    num_train_epochs=1,\n",
    "    logging_first_step=True,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=50,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=300,\n",
    "    fp16=False,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    save_total_limit=3,\n",
    ")\n",
    "\n",
    "#load_best_model_at_end=True,     # Load the best model at the end of training\n",
    "#metric_for_best_model=\"accuracy\" # Metric to use for the best model\n",
    "#save_total_limit\n",
    "#check different bach_size: 32, or 64."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds, labels = p\n",
    "    preds = np.argmax(preds, axis=1)\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary')\n",
    "    return {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=arguments,\n",
    "    train_dataset=tokenized_datasets[\"train\"].shuffle(seed=42),\n",
    "    eval_dataset=tokenized_datasets[\"validation\"].shuffle(seed=42),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 11113), started 0:32:19 ago. (Use '!kill 11113' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./output/runs\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 300/3542 [32:07<5:47:13,  6.43s/it]\n",
      "                                                  \n",
      "\n",
      "  0%|          | 1/3542 [00:05<5:35:35,  5.69s/it]  \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7393, 'grad_norm': 9.898111343383789, 'learning_rate': 4.9985883681535854e-05, 'epoch': 0.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "\n",
      "  1%|▏         | 50/3542 [01:49<2:01:15,  2.08s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5806, 'grad_norm': 2.1417925357818604, 'learning_rate': 4.9294184076792775e-05, 'epoch': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "\n",
      "  3%|▎         | 100/3542 [03:33<1:59:03,  2.08s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5462, 'grad_norm': 2.6905908584594727, 'learning_rate': 4.858836815358554e-05, 'epoch': 0.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "\n",
      "  4%|▍         | 150/3542 [05:18<2:09:38,  2.29s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5432, 'grad_norm': 32.46713638305664, 'learning_rate': 4.788255223037832e-05, 'epoch': 0.04}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "\n",
      "  6%|▌         | 200/3542 [07:11<2:04:50,  2.24s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5415, 'grad_norm': 12.382285118103027, 'learning_rate': 4.7176736307171095e-05, 'epoch': 0.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "\n",
      "  7%|▋         | 250/3542 [09:02<2:03:21,  2.25s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5357, 'grad_norm': 5.774582862854004, 'learning_rate': 4.647092038396386e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "\n",
      "  8%|▊         | 300/3542 [10:54<2:01:19,  2.25s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5654, 'grad_norm': 3.9634294509887695, 'learning_rate': 4.5765104460756634e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "\u001b[A                                              \n",
      "\n",
      "  8%|▊         | 300/3542 [14:36<2:01:19,  2.25s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5398724675178528, 'eval_accuracy': 0.7584814216478191, 'eval_precision': 0.5867768595041323, 'eval_recall': 0.1147011308562197, 'eval_f1': 0.1918918918918919, 'eval_runtime': 221.7613, 'eval_samples_per_second': 22.33, 'eval_steps_per_second': 1.398, 'epoch': 0.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\n",
      " 10%|▉         | 350/3542 [16:32<1:58:26,  2.23s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5166, 'grad_norm': 4.05230712890625, 'learning_rate': 4.505928853754941e-05, 'epoch': 0.1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "\n",
      " 11%|█▏        | 400/3542 [18:24<1:56:48,  2.23s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.501, 'grad_norm': 3.482322931289673, 'learning_rate': 4.435347261434219e-05, 'epoch': 0.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "\n",
      " 13%|█▎        | 450/3542 [20:16<1:55:13,  2.24s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4918, 'grad_norm': 5.829156875610352, 'learning_rate': 4.364765669113495e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "\n",
      " 14%|█▍        | 500/3542 [22:08<1:53:16,  2.23s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4807, 'grad_norm': 11.87427043914795, 'learning_rate': 4.2941840767927726e-05, 'epoch': 0.14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "\n",
      " 16%|█▌        | 550/3542 [24:00<1:51:45,  2.24s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5247, 'grad_norm': 13.048454284667969, 'learning_rate': 4.22360248447205e-05, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "\n",
      " 17%|█▋        | 600/3542 [25:52<1:49:51,  2.24s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4409, 'grad_norm': 24.058347702026367, 'learning_rate': 4.153020892151327e-05, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "\u001b[A                                              \n",
      "\n",
      " 17%|█▋        | 600/3542 [29:34<1:49:51,  2.24s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.0016645193099976, 'eval_accuracy': 0.5379644588045234, 'eval_precision': 0.28269867549668876, 'eval_recall': 0.5516962843295639, 'eval_f1': 0.3738368910782704, 'eval_runtime': 221.8456, 'eval_samples_per_second': 22.322, 'eval_steps_per_second': 1.397, 'epoch': 0.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\n",
      " 18%|█▊        | 650/3542 [31:30<1:41:37,  2.11s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4822, 'grad_norm': 3.308317184448242, 'learning_rate': 4.0824392998306045e-05, 'epoch': 0.18}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "\n",
      " 20%|█▉        | 700/3542 [33:15<1:38:17,  2.08s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4763, 'grad_norm': 4.01617431640625, 'learning_rate': 4.011857707509882e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "\n",
      " 21%|██        | 750/3542 [34:58<1:36:30,  2.07s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4844, 'grad_norm': 3.27064847946167, 'learning_rate': 3.9412761151891584e-05, 'epoch': 0.21}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "\n",
      " 23%|██▎       | 800/3542 [36:42<1:34:38,  2.07s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4781, 'grad_norm': 9.02314281463623, 'learning_rate': 3.870694522868436e-05, 'epoch': 0.23}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "\n",
      " 24%|██▍       | 850/3542 [38:28<1:42:26,  2.28s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4852, 'grad_norm': 52.973052978515625, 'learning_rate': 3.800112930547714e-05, 'epoch': 0.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "\n",
      " 25%|██▌       | 900/3542 [40:20<1:38:45,  2.24s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.485, 'grad_norm': 6.909114837646484, 'learning_rate': 3.729531338226991e-05, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      "\u001b[A                                              \n",
      "\n",
      " 25%|██▌       | 900/3542 [44:02<1:38:45,  2.24s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5274370312690735, 'eval_accuracy': 0.7625201938610663, 'eval_precision': 0.5446685878962536, 'eval_recall': 0.3053311793214863, 'eval_f1': 0.391304347826087, 'eval_runtime': 222.0771, 'eval_samples_per_second': 22.299, 'eval_steps_per_second': 1.396, 'epoch': 0.25}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\n",
      " 27%|██▋       | 950/3542 [45:59<1:37:06,  2.25s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.447, 'grad_norm': 17.571975708007812, 'learning_rate': 3.6589497459062677e-05, 'epoch': 0.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\n",
      " 28%|██▊       | 1000/3542 [47:51<1:35:05,  2.24s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4703, 'grad_norm': 19.123497009277344, 'learning_rate': 3.588368153585545e-05, 'epoch': 0.28}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\n",
      " 30%|██▉       | 1050/3542 [49:42<1:27:33,  2.11s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4916, 'grad_norm': 7.068881988525391, 'learning_rate': 3.517786561264822e-05, 'epoch': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\n",
      " 31%|███       | 1100/3542 [51:29<1:23:43,  2.06s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.434, 'grad_norm': 9.747776985168457, 'learning_rate': 3.4472049689440996e-05, 'epoch': 0.31}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\n",
      " 32%|███▏      | 1150/3542 [53:12<1:21:53,  2.05s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4641, 'grad_norm': 5.713693141937256, 'learning_rate': 3.376623376623377e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\n",
      " 34%|███▍      | 1200/3542 [54:58<1:21:10,  2.08s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4685, 'grad_norm': 8.105915069580078, 'learning_rate': 3.306041784302654e-05, 'epoch': 0.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\u001b[A                                              \n",
      "\n",
      " 34%|███▍      | 1200/3542 [58:28<1:21:10,  2.08s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5611861944198608, 'eval_accuracy': 0.7316235864297254, 'eval_precision': 0.4517497348886532, 'eval_recall': 0.3441033925686591, 'eval_f1': 0.390646492434663, 'eval_runtime': 210.3336, 'eval_samples_per_second': 23.544, 'eval_steps_per_second': 1.474, 'epoch': 0.34}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      "\n",
      " 35%|███▌      | 1250/3542 [1:00:19<1:19:48,  2.09s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4438, 'grad_norm': 20.903188705444336, 'learning_rate': 3.235460191981931e-05, 'epoch': 0.35}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      "\n",
      " 37%|███▋      | 1300/3542 [1:02:06<1:16:46,  2.05s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4386, 'grad_norm': 8.268744468688965, 'learning_rate': 3.164878599661209e-05, 'epoch': 0.37}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      "\n",
      " 38%|███▊      | 1350/3542 [1:03:49<1:15:14,  2.06s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4443, 'grad_norm': 10.602713584899902, 'learning_rate': 3.094297007340486e-05, 'epoch': 0.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      "\n",
      " 40%|███▉      | 1400/3542 [1:05:32<1:13:51,  2.07s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4517, 'grad_norm': 7.063538551330566, 'learning_rate': 3.0237154150197627e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      "\n",
      " 41%|████      | 1450/3542 [1:07:15<1:11:36,  2.05s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3855, 'grad_norm': 9.544124603271484, 'learning_rate': 2.95313382269904e-05, 'epoch': 0.41}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      "\n",
      " 42%|████▏     | 1500/3542 [1:08:58<1:09:44,  2.05s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4155, 'grad_norm': 8.02658748626709, 'learning_rate': 2.8825522303783176e-05, 'epoch': 0.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      "\u001b[A                                              \n",
      "\n",
      " 42%|████▏     | 1500/3542 [1:12:24<1:09:44,  2.05s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.8618637323379517, 'eval_accuracy': 0.6512520193861067, 'eval_precision': 0.35208711433756806, 'eval_recall': 0.4701130856219709, 'eval_f1': 0.4026288481494293, 'eval_runtime': 206.4088, 'eval_samples_per_second': 23.991, 'eval_steps_per_second': 1.502, 'epoch': 0.42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      "\n",
      " 44%|████▍     | 1550/3542 [1:14:11<1:08:19,  2.06s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4199, 'grad_norm': 8.687762260437012, 'learning_rate': 2.811970638057595e-05, 'epoch': 0.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      "\n",
      " 45%|████▌     | 1600/3542 [1:15:55<1:07:28,  2.08s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4341, 'grad_norm': 99.5114517211914, 'learning_rate': 2.741389045736872e-05, 'epoch': 0.45}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      "\n",
      " 47%|████▋     | 1650/3542 [1:17:39<1:05:05,  2.06s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3854, 'grad_norm': 3.823646306991577, 'learning_rate': 2.6708074534161492e-05, 'epoch': 0.47}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      "\n",
      " 48%|████▊     | 1700/3542 [1:19:22<1:04:15,  2.09s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3466, 'grad_norm': 6.005309104919434, 'learning_rate': 2.6002258610954265e-05, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      "\n",
      " 49%|████▉     | 1750/3542 [1:21:07<1:02:37,  2.10s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4282, 'grad_norm': 32.171348571777344, 'learning_rate': 2.5296442687747035e-05, 'epoch': 0.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      "\n",
      " 51%|█████     | 1800/3542 [1:22:50<1:00:00,  2.07s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4373, 'grad_norm': 30.86895179748535, 'learning_rate': 2.4590626764539808e-05, 'epoch': 0.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      "\u001b[A                                              \n",
      "\n",
      " 51%|█████     | 1800/3542 [1:26:18<1:00:00,  2.07s/it]\n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6319444179534912, 'eval_accuracy': 0.7382875605815832, 'eval_precision': 0.4722753346080306, 'eval_recall': 0.3990306946688207, 'eval_f1': 0.43257443082311736, 'eval_runtime': 207.7438, 'eval_samples_per_second': 23.837, 'eval_steps_per_second': 1.492, 'epoch': 0.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      "\n",
      " 52%|█████▏    | 1850/3542 [1:28:05<58:11,  2.06s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4283, 'grad_norm': 6.653993606567383, 'learning_rate': 2.388481084133258e-05, 'epoch': 0.52}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\n",
      " 54%|█████▎    | 1900/3542 [1:29:49<56:30,  2.06s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4236, 'grad_norm': 9.6743803024292, 'learning_rate': 2.3178994918125354e-05, 'epoch': 0.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      "\n",
      " 55%|█████▌    | 1950/3542 [1:31:35<55:50,  2.10s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3984, 'grad_norm': 5.314972877502441, 'learning_rate': 2.2473178994918127e-05, 'epoch': 0.55}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\n",
      " 56%|█████▋    | 2000/3542 [1:33:21<53:32,  2.08s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4194, 'grad_norm': 3.4049394130706787, 'learning_rate': 2.17673630717109e-05, 'epoch': 0.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\n",
      " 58%|█████▊    | 2050/3542 [1:35:06<52:15,  2.10s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4016, 'grad_norm': 3.996960401535034, 'learning_rate': 2.106154714850367e-05, 'epoch': 0.58}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\n",
      " 59%|█████▉    | 2100/3542 [1:36:51<49:56,  2.08s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4082, 'grad_norm': 9.478657722473145, 'learning_rate': 2.0355731225296443e-05, 'epoch': 0.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\u001b[A                                              \n",
      "\n",
      " 59%|█████▉    | 2100/3542 [1:40:20<49:56,  2.08s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6938889622688293, 'eval_accuracy': 0.6657915993537964, 'eval_precision': 0.3791304347826087, 'eval_recall': 0.5282714054927302, 'eval_f1': 0.4414444819439757, 'eval_runtime': 208.7631, 'eval_samples_per_second': 23.721, 'eval_steps_per_second': 1.485, 'epoch': 0.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      "\n",
      " 61%|██████    | 2150/3542 [1:42:15<52:17,  2.25s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4208, 'grad_norm': 13.300623893737793, 'learning_rate': 1.9649915302089216e-05, 'epoch': 0.61}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\n",
      " 62%|██████▏   | 2200/3542 [1:44:07<50:05,  2.24s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.402, 'grad_norm': 3.503796100616455, 'learning_rate': 1.894409937888199e-05, 'epoch': 0.62}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\n",
      " 64%|██████▎   | 2250/3542 [1:45:59<48:00,  2.23s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4025, 'grad_norm': 5.084552764892578, 'learning_rate': 1.8238283455674762e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\n",
      " 65%|██████▍   | 2300/3542 [1:47:51<46:31,  2.25s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4337, 'grad_norm': 56.229244232177734, 'learning_rate': 1.7532467532467535e-05, 'epoch': 0.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\n",
      " 66%|██████▋   | 2350/3542 [1:49:43<44:25,  2.24s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4242, 'grad_norm': 8.746916770935059, 'learning_rate': 1.6826651609260305e-05, 'epoch': 0.66}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\n",
      " 68%|██████▊   | 2400/3542 [1:51:35<42:37,  2.24s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3885, 'grad_norm': 9.898653030395508, 'learning_rate': 1.6120835686053078e-05, 'epoch': 0.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\u001b[A                                              \n",
      "\n",
      " 68%|██████▊   | 2400/3542 [1:55:17<42:37,  2.24s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.701611340045929, 'eval_accuracy': 0.6904281098546042, 'eval_precision': 0.3837667454688731, 'eval_recall': 0.39337641357027464, 'eval_f1': 0.38851216593538096, 'eval_runtime': 222.1484, 'eval_samples_per_second': 22.291, 'eval_steps_per_second': 1.395, 'epoch': 0.68}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      "\n",
      " 69%|██████▉   | 2450/3542 [1:57:05<37:42,  2.07s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3927, 'grad_norm': 6.687380790710449, 'learning_rate': 1.541501976284585e-05, 'epoch': 0.69}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\n",
      " 71%|███████   | 2500/3542 [1:58:49<35:58,  2.07s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3951, 'grad_norm': 14.514644622802734, 'learning_rate': 1.4709203839638622e-05, 'epoch': 0.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\n",
      " 72%|███████▏  | 2550/3542 [2:00:32<34:11,  2.07s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3729, 'grad_norm': 16.838741302490234, 'learning_rate': 1.4003387916431395e-05, 'epoch': 0.72}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\n",
      " 73%|███████▎  | 2600/3542 [2:02:16<32:40,  2.08s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.418, 'grad_norm': 8.816659927368164, 'learning_rate': 1.3297571993224166e-05, 'epoch': 0.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\n",
      " 75%|███████▍  | 2650/3542 [2:04:00<30:43,  2.07s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3734, 'grad_norm': 12.079802513122559, 'learning_rate': 1.2591756070016941e-05, 'epoch': 0.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\n",
      " 76%|███████▌  | 2700/3542 [2:05:43<29:08,  2.08s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3527, 'grad_norm': 7.693946361541748, 'learning_rate': 1.1885940146809712e-05, 'epoch': 0.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\u001b[A                                              \n",
      "\n",
      " 76%|███████▌  | 2700/3542 [2:09:14<29:08,  2.08s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.604396402835846, 'eval_accuracy': 0.7211227786752827, 'eval_precision': 0.4424778761061947, 'eval_recall': 0.44426494345718903, 'eval_f1': 0.4433696090286175, 'eval_runtime': 210.0815, 'eval_samples_per_second': 23.572, 'eval_steps_per_second': 1.476, 'epoch': 0.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      "\n",
      " 78%|███████▊  | 2750/3542 [2:11:02<27:19,  2.07s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3895, 'grad_norm': 4.546485424041748, 'learning_rate': 1.1180124223602485e-05, 'epoch': 0.78}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\n",
      " 79%|███████▉  | 2800/3542 [2:12:45<25:35,  2.07s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3768, 'grad_norm': 18.083559036254883, 'learning_rate': 1.0474308300395258e-05, 'epoch': 0.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\n",
      " 80%|████████  | 2850/3542 [2:14:33<23:54,  2.07s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3844, 'grad_norm': 6.071068286895752, 'learning_rate': 9.76849237718803e-06, 'epoch': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\n",
      " 82%|████████▏ | 2900/3542 [2:16:17<22:13,  2.08s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4116, 'grad_norm': 5.689145088195801, 'learning_rate': 9.062676453980803e-06, 'epoch': 0.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\n",
      " 83%|████████▎ | 2950/3542 [2:18:00<20:24,  2.07s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.375, 'grad_norm': 5.815298557281494, 'learning_rate': 8.356860530773574e-06, 'epoch': 0.83}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\n",
      " 85%|████████▍ | 3000/3542 [2:19:50<20:47,  2.30s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3993, 'grad_norm': 10.620655059814453, 'learning_rate': 7.651044607566347e-06, 'epoch': 0.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\u001b[A                                              \n",
      "\n",
      " 85%|████████▍ | 3000/3542 [2:23:19<20:47,  2.30s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7162923812866211, 'eval_accuracy': 0.6647819063004846, 'eval_precision': 0.36845386533665836, 'eval_recall': 0.4773828756058158, 'eval_f1': 0.4159042927515834, 'eval_runtime': 208.6572, 'eval_samples_per_second': 23.733, 'eval_steps_per_second': 1.486, 'epoch': 0.85}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      "\n",
      " 86%|████████▌ | 3050/3542 [2:25:09<17:05,  2.08s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3816, 'grad_norm': 7.570056915283203, 'learning_rate': 6.9452286843591186e-06, 'epoch': 0.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\n",
      " 88%|████████▊ | 3100/3542 [2:26:52<15:09,  2.06s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3398, 'grad_norm': 8.735584259033203, 'learning_rate': 6.239412761151892e-06, 'epoch': 0.88}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\n",
      " 89%|████████▉ | 3150/3542 [2:28:36<13:29,  2.07s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3475, 'grad_norm': 11.237716674804688, 'learning_rate': 5.533596837944665e-06, 'epoch': 0.89}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\n",
      " 90%|█████████ | 3200/3542 [2:30:21<12:46,  2.24s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3291, 'grad_norm': 3.380521774291992, 'learning_rate': 4.827780914737437e-06, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\n",
      " 92%|█████████▏| 3250/3542 [2:32:13<10:52,  2.23s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3509, 'grad_norm': 14.01962947845459, 'learning_rate': 4.121964991530209e-06, 'epoch': 0.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\n",
      " 93%|█████████▎| 3300/3542 [2:34:03<08:22,  2.08s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3917, 'grad_norm': 8.876749992370605, 'learning_rate': 3.4161490683229816e-06, 'epoch': 0.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\u001b[A                                              \n",
      "\n",
      " 93%|█████████▎| 3300/3542 [2:37:32<08:22,  2.08s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6540948748588562, 'eval_accuracy': 0.692043618739903, 'eval_precision': 0.4057780695994747, 'eval_recall': 0.4991922455573506, 'eval_f1': 0.4476638898949656, 'eval_runtime': 208.9074, 'eval_samples_per_second': 23.704, 'eval_steps_per_second': 1.484, 'epoch': 0.93}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      "\n",
      " 95%|█████████▍| 3350/3542 [2:39:20<06:37,  2.07s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3465, 'grad_norm': 9.992505073547363, 'learning_rate': 2.7103331451157542e-06, 'epoch': 0.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\n",
      " 96%|█████████▌| 3400/3542 [2:41:03<04:53,  2.07s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3671, 'grad_norm': 11.972445487976074, 'learning_rate': 2.0045172219085264e-06, 'epoch': 0.96}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\n",
      " 97%|█████████▋| 3450/3542 [2:42:47<03:10,  2.07s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3588, 'grad_norm': 8.486315727233887, 'learning_rate': 1.2987012987012988e-06, 'epoch': 0.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\n",
      " 99%|█████████▉| 3500/3542 [2:44:30<01:26,  2.07s/it] \n",
      "\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3588, 'grad_norm': 5.945509433746338, 'learning_rate': 5.928853754940711e-07, 'epoch': 0.99}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      "\n",
      "100%|██████████| 3542/3542 [2:46:03<00:00,  2.14s/it] \n",
      "100%|██████████| 3542/3542 [2:46:03<00:00,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 9963.7699, 'train_samples_per_second': 5.687, 'train_steps_per_second': 0.355, 'train_loss': 0.42961667110393575, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3542, training_loss=0.42961667110393575, metrics={'train_runtime': 9963.7699, 'train_samples_per_second': 5.687, 'train_steps_per_second': 0.355, 'total_flos': 1.490892484091904e+16, 'train_loss': 0.42961667110393575, 'epoch': 1.0})"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wyprobuj\n",
    "- f1 do uczenia\n",
    "- nie separator </s> tylko tak, jak w przykładzie: pytanie: kontekst:\n",
    "- nie zawsze 3x zła 1x dobra odp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./best_model_f1/tokenizer_config.json',\n",
       " './best_model_f1/special_tokens_map.json',\n",
       " './best_model_f1/vocab.json',\n",
       " './best_model_f1/merges.txt',\n",
       " './best_model_f1/added_tokens.json',\n",
       " './best_model_f1/tokenizer.json')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained('./best_model_f1')\n",
    "pl_tokenizer.save_pretrained('./best_model_f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to delete index 'mw_nlp_lab5_test': {\"error\":{\"root_cause\":[{\"type\":\"index_not_found_exception\",\"reason\":\"no such index [mw_nlp_lab5_test]\",\"resource.type\":\"index_or_alias\",\"resource.id\":\"mw_nlp_lab5_test\",\"index_uuid\":\"_na_\",\"index\":\"mw_nlp_lab5_test\"}],\"type\":\"index_not_found_exception\",\"reason\":\"no such index [mw_nlp_lab5_test]\",\"resource.type\":\"index_or_alias\",\"resource.id\":\"mw_nlp_lab5_test\",\"index_uuid\":\"_na_\",\"index\":\"mw_nlp_lab5_test\"},\"status\":404}\n",
      "Index created.\n",
      "All documents indexed successfully.\n"
     ]
    }
   ],
   "source": [
    "test_query_to_corpus_dict = utils.prepare_fiqa_qrels(qrels, ['test'])\n",
    "test_corpus_dict = utils.prepare_fiqa_corpus_related_to_selected_subsets(corpus, test_query_to_corpus_dict, True)\n",
    "\n",
    "test_index_name = \"mw_nlp_lab5_test\"\n",
    "fts_url, test_index_url = utils.create_fts_index(test_index_name)\n",
    "utils.bulk_load(fts_url, test_index_name, test_corpus_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = collect_training_dataset(test_index_url, test_corpus_dict, ['test'], separator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 6824/6824 [00:01<00:00, 4364.43 examples/s]\n",
      "100%|██████████| 427/427 [04:55<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5758367776870728, 'eval_accuracy': 0.738569753810082, 'eval_precision': 0.4785005512679162, 'eval_recall': 0.5087924970691676, 'eval_f1': 0.49318181818181817, 'eval_runtime': 300.216, 'eval_samples_per_second': 22.73, 'eval_steps_per_second': 1.422, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenized_test_datasets = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "results = trainer.evaluate(tokenized_test_datasets)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m pl_tokenizer(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSprzedajesz w serwisie eBay bez PayPal?\u001b[39m\u001b[38;5;124m\"\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_length\u001b[39m\u001b[38;5;124m\"\u001b[39m, truncation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m----> 6\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ds/_semestr_9/przetwarzanie_jezyka_naturalnego/labs/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ds/_semestr_9/przetwarzanie_jezyka_naturalnego/labs/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/ds/_semestr_9/przetwarzanie_jezyka_naturalnego/labs/.venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1668\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1660\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1661\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1662\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1663\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1664\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1665\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1666\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1668\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1674\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1675\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1676\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1678\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1680\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m   1682\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[0;32m~/Documents/ds/_semestr_9/przetwarzanie_jezyka_naturalnego/labs/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/ds/_semestr_9/przetwarzanie_jezyka_naturalnego/labs/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/Documents/ds/_semestr_9/przetwarzanie_jezyka_naturalnego/labs/.venv/lib/python3.12/site-packages/transformers/models/bert/modeling_bert.py:1058\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1057\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarn_if_padding_and_no_attention_mask(input_ids, attention_mask)\n\u001b[0;32m-> 1058\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m \u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m()\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1060\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m inputs_embeds\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "input = pl_tokenizer(\"Sprzedajesz w serwisie eBay bez PayPal?\", padding=\"max_length\", truncation=True)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to delete index 'mw_nlp_lab5_all': {\"error\":{\"root_cause\":[{\"type\":\"index_not_found_exception\",\"reason\":\"no such index [mw_nlp_lab5_all]\",\"resource.type\":\"index_or_alias\",\"resource.id\":\"mw_nlp_lab5_all\",\"index_uuid\":\"_na_\",\"index\":\"mw_nlp_lab5_all\"}],\"type\":\"index_not_found_exception\",\"reason\":\"no such index [mw_nlp_lab5_all]\",\"resource.type\":\"index_or_alias\",\"resource.id\":\"mw_nlp_lab5_all\",\"index_uuid\":\"_na_\",\"index\":\"mw_nlp_lab5_all\"},\"status\":404}\n",
      "Index created.\n",
      "All documents indexed successfully.\n"
     ]
    }
   ],
   "source": [
    "all_corpus_dict = utils.prepare_fiqa_corpus_related_to_selected_subsets(corpus, {}, False)\n",
    "\n",
    "all_index_name = \"mw_nlp_lab5_all\"\n",
    "fts_url, all_index_url = utils.create_fts_index(all_index_name)\n",
    "utils.bulk_load(fts_url, all_index_name, all_corpus_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.20438239758848611,\n",
       " 0.2640681225725909,\n",
       " 0.0,\n",
       " 0.5,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.6131471927654584,\n",
       " 0.16716045496620227,\n",
       " 1.0,\n",
       " 0.3333333333333333,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.18495352221149364,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.09478836436955078,\n",
       " 0.09010000865236768,\n",
       " 0.7977228895450266,\n",
       " 0.6309297535714575,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.6131471927654584,\n",
       " 0.0,\n",
       " 0.08671382849411972,\n",
       " 0.6309297535714575,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.21109268758922906,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.5802792108518124,\n",
       " 0.21840743681816419,\n",
       " 0.6992148198508501,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.3065735963827292,\n",
       " 0.2960819109658652,\n",
       " 0.20438239758848611,\n",
       " 0.11751610475642714,\n",
       " 0.0,\n",
       " 0.16812753627111746,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.3333333333333333,\n",
       " 0.5,\n",
       " 0.6309297535714575,\n",
       " 0.5689918564790247,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.2890648263178879,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.43830722522726884,\n",
       " 0.19342640361727081,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.24630238874073,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.46927872602275644,\n",
       " 0.7653606369886217,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.5969412532155237,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.19342640361727081,\n",
       " 0.46927872602275644,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.8710785440003369,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.6131471927654584,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.86034433104172,\n",
       " 0.20210734650054757,\n",
       " 0.6309297535714575,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.5,\n",
       " 0.2890648263178879,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.22009176629808017,\n",
       " 0.7757386182436072,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.6131471927654584,\n",
       " 0.46927872602275644,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.23719771276929622,\n",
       " 0.2429718246796358,\n",
       " 0.43067655807339306,\n",
       " 0.6131471927654584,\n",
       " 0.3257192188287456,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.43067655807339306,\n",
       " 0.0,\n",
       " 0.19092086617893467,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.9828920819566879,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.3903800499921017,\n",
       " 0.38685280723454163,\n",
       " 0.7974049492783576,\n",
       " 0.0,\n",
       " 0.1480409554829326,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.35914753008966527,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.6131471927654584,\n",
       " 0.0,\n",
       " 0.5,\n",
       " 0.0,\n",
       " 0.6131471927654584,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.6131471927654584,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.3391602052736161,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.4632423659320675,\n",
       " 0.8315546295836225,\n",
       " 0.0,\n",
       " 0.21840743681816419,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.2640681225725909,\n",
       " 0.23119123707664177,\n",
       " 0.38685280723454163,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.5,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.3501483019834802,\n",
       " 0.0,\n",
       " 0.46927872602275644,\n",
       " 0.10633668103022985,\n",
       " 0.2890648263178879,\n",
       " 0.5,\n",
       " 0.28371255449703187,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.38685280723454163,\n",
       " 0.6131471927654584,\n",
       " 0.43067655807339306,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.3333333333333333,\n",
       " 0.0,\n",
       " 0.8200261225503443,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.20438239758848611,\n",
       " 0.2960819109658652,\n",
       " 1.0,\n",
       " 0.21840743681816419,\n",
       " 0.07979453856244817,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.6131471927654584,\n",
       " 0.8048099750039491,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.46927872602275644,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.46927872602275644,\n",
       " 0.0,\n",
       " 0.19092086617893467,\n",
       " 0.0,\n",
       " 0.12647135138382856,\n",
       " 0.0,\n",
       " 0.6131471927654584,\n",
       " 0.0,\n",
       " 0.8065735963827293,\n",
       " 0.6257049680303419,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.6131471927654584,\n",
       " 0.45749452618986164,\n",
       " 0.13120507751234178,\n",
       " 0.6131471927654584,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.5413996682199069,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.5,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.2816249726597774,\n",
       " 0.8065735963827293,\n",
       " 0.0,\n",
       " 0.2960819109658652,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.5,\n",
       " 0.0,\n",
       " 0.28371255449703187,\n",
       " 0.6309297535714575,\n",
       " 0.0,\n",
       " 0.6131471927654584,\n",
       " 0.13012668333070054,\n",
       " 0.0,\n",
       " 0.20438239758848611,\n",
       " 0.0,\n",
       " 0.38685280723454163,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.3903800499921017,\n",
       " 0.5857421563596757,\n",
       " 0.0,\n",
       " 0.43067655807339306,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.6713860725233041,\n",
       " 0.18154179253735267,\n",
       " 0.38685280723454163,\n",
       " 0.0,\n",
       " 0.31546487678572877,\n",
       " 0.0,\n",
       " 0.1480409554829326,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.3562071871080222,\n",
       " 0.15130120674940672,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.3391602052736161,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.21252302622743086,\n",
       " 0.0,\n",
       " 0.6366824387328317,\n",
       " 0.0,\n",
       " 0.3191471544989227,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.13905617951077562,\n",
       " 0.6309297535714575,\n",
       " 0.0,\n",
       " 0.21840743681816419,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.3903800499921017,\n",
       " 0.0,\n",
       " 0.6131471927654584,\n",
       " 0.3903800499921017,\n",
       " 0.38685280723454163,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.46927872602275644,\n",
       " 0.0,\n",
       " 0.3562071871080222,\n",
       " 0.0,\n",
       " 0.38685280723454163,\n",
       " 0.13565197343244778,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.3391602052736161,\n",
       " 0.0,\n",
       " 0.23719771276929622,\n",
       " 0.43067655807339306,\n",
       " 0.0,\n",
       " 0.38685280723454163,\n",
       " 0.13743816645714543,\n",
       " 0.2640681225725909,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.1480409554829326,\n",
       " 0.0,\n",
       " 0.20210734650054757,\n",
       " 0.27191445400928355,\n",
       " 0.0,\n",
       " 0.3010299956639812,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.30260241349881345,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.46927872602275644,\n",
       " 0.16716045496620227,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.18457569677956817,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.6131471927654584,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.38685280723454163,\n",
       " 0.30260241349881345,\n",
       " 0.13565197343244778,\n",
       " 0.0,\n",
       " 0.8318724637288826,\n",
       " 0.16716045496620227,\n",
       " 0.6309297535714575,\n",
       " 0.0,\n",
       " 0.2640681225725909,\n",
       " 0.0,\n",
       " 0.5032251913410369,\n",
       " 0.20210734650054757,\n",
       " 0.0,\n",
       " 0.19342640361727081,\n",
       " 0.8854598815714874,\n",
       " 0.0,\n",
       " 0.24410763567406352,\n",
       " 0.7653606369886217,\n",
       " 1.0,\n",
       " 0.6131471927654584,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.21840743681816419,\n",
       " 0.0,\n",
       " 0.43067655807339306,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.6309297535714575,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.2890648263178879,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.20483424751859086,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.6309297535714575,\n",
       " 0.8175295903539445,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.11751610475642714,\n",
       " 0.5,\n",
       " 0.6131471927654584,\n",
       " 0.5437713091520254,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.5,\n",
       " 0.0,\n",
       " 0.6509209298071326,\n",
       " 0.46927872602275644,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.38685280723454163,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.2558209594125084,\n",
       " 0.2960819109658652,\n",
       " 0.0,\n",
       " 0.3071837157818931,\n",
       " 0.0,\n",
       " 0.13743816645714543,\n",
       " 0.0,\n",
       " 0.3903800499921017,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.20438239758848611,\n",
       " 0.11751610475642714,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.17723928678404774,\n",
       " 0.0,\n",
       " 0.6366824387328317,\n",
       " 0.0,\n",
       " 0.36637716437781265,\n",
       " 0.0,\n",
       " 0.7039180890341347,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.15642624200758548,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.6309297535714575,\n",
       " 0.14629191738978584,\n",
       " 0.8772153153380493,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.384266559722312,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.07979453856244817,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.2640681225725909,\n",
       " 0.3562071871080222,\n",
       " 0.46927872602275644,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.2640681225725909,\n",
       " 0.2741708125981702,\n",
       " 0.0,\n",
       " 0.9197207891481876,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.09109240322345806,\n",
       " 0.0,\n",
       " 0.19342640361727081,\n",
       " 0.5531464700081437,\n",
       " 0.0,\n",
       " 0.9197207891481876,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.3065735963827292,\n",
       " 0.6235744328990731,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.6444638628256741,\n",
       " 0.46927872602275644,\n",
       " 0.0,\n",
       " 0.7653606369886217,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.38162168437253385,\n",
       " 0.13565197343244778,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.6309297535714575,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.1480409554829326,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.46927872602275644,\n",
       " 0.8175295903539445,\n",
       " 0.7653606369886217,\n",
       " 0.0,\n",
       " 0.46927872602275644,\n",
       " 0.6131471927654584,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.18457569677956817,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.2765732350040718,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.3065735963827292,\n",
       " 0.3903800499921017,\n",
       " 0.5307212739772434,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.6131471927654584,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0979129253499678,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.5,\n",
       " 0.0,\n",
       " 0.38685280723454163,\n",
       " 0.0,\n",
       " 0.7039180890341347,\n",
       " 0.2640681225725909,\n",
       " 0.38685280723454163,\n",
       " 0.11751610475642714,\n",
       " 0.6309297535714575,\n",
       " 0.0,\n",
       " 0.18154179253735267,\n",
       " 0.0,\n",
       " 0.7039180890341347,\n",
       " 0.2640681225725909,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.46927872602275644,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.5855700749881525,\n",
       " 0.0,\n",
       " 0.6131471927654584,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.20210734650054757,\n",
       " 0.0,\n",
       " 0.38685280723454163,\n",
       " 0.6131471927654584,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.8048099750039491,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.2960819109658652,\n",
       " 0.0,\n",
       " 0.46927872602275644,\n",
       " 1.0]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_query_to_corpus_dict = utils.prepare_fiqa_qrels(qrels, ['test'])\n",
    "test_queries_dict = utils.prepare_fiqa_queries_for_selected_subset(queries, test_query_to_corpus_dict)\n",
    "\n",
    "def rerank(texts, model):\n",
    "    inputs = pl_tokenizer(\n",
    "        texts,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,  # Truncate to the model's max length\n",
    "        return_tensors=\"pt\"  # Return PyTorch tensors\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    logits = outputs.logits\n",
    "    \n",
    ")\n",
    "\n",
    "utils.calculate_ndcgs(test_queries_dict, test_query_to_corpus_dict, all_index_url, 'text', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'lab5_utils' from '/Users/mwardynski/Documents/ds/_semestr_9/przetwarzanie_jezyka_naturalnego/labs/lab5/lab5_utils.py'>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import lab5_utils\n",
    "importlib.reload(lab5_utils)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
