{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marcin Wardyński  \n",
    "czwartek, 8:00\n",
    "\n",
    "### Laboratorium 5: Klasyfikacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mwardynski/Documents/ds/_semestr_9/przetwarzanie_jezyka_naturalnego/labs/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import lab5_utils as utils\n",
    "\n",
    "corpus, queries, qrels = utils.load_fiqa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO check the intersection between test, validation and test. Reconsider sizes of the datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "pl_tokenizer = AutoTokenizer.from_pretrained(\"allegro/herbert-base-cased\")\n",
    "separator = pl_tokenizer.sep_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vate_query_to_corpus_dict = utils.prepare_fiqa_qrels(qrels, ['validation', 'test'])\n",
    "no_vate_corpus_dict = utils.prepare_fiqa_corpus_related_to_selected_subsets(corpus, vate_query_to_corpus_dict, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'mw_nlp_lab5_train' deleted successfully.\n",
      "Index created.\n",
      "All documents indexed successfully.\n"
     ]
    }
   ],
   "source": [
    "train_index_name = \"mw_nlp_lab5_train\"\n",
    "fts_url, train_index_url = utils.create_fts_index(train_index_name)\n",
    "utils.bulk_load(fts_url, train_index_name, no_vate_corpus_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'mw_nlp_lab5_validation' deleted successfully.\n",
      "Index created.\n",
      "All documents indexed successfully.\n"
     ]
    }
   ],
   "source": [
    "va_query_to_corpus_dict = utils.prepare_fiqa_qrels(qrels, ['validation'])\n",
    "va_corpus_dict = utils.prepare_fiqa_corpus_related_to_selected_subsets(corpus, va_query_to_corpus_dict, True)\n",
    "\n",
    "validation_index_name = \"mw_nlp_lab5_validation\"\n",
    "fts_url, validation_index_url = utils.create_fts_index(validation_index_name)\n",
    "utils.bulk_load(fts_url, validation_index_name, va_corpus_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "def collect_training_dataset(index_url, corpus_dict, subsets, separator):\n",
    "    query_to_corpus_dict = utils.prepare_fiqa_qrels(qrels, subsets)\n",
    "    queries_dict = utils.prepare_fiqa_queries_for_selected_subset(queries, query_to_corpus_dict)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for q_id, q_text in queries_dict.items():\n",
    "        collect_passages_for_query(q_id, q_text, corpus_dict, query_to_corpus_dict, index_url, results, separator)\n",
    "\n",
    "    return Dataset.from_list(results)\n",
    "\n",
    "def collect_passages_for_query(q_id, q_text, p_dict, q_to_p_dict, index_url, results, separator):\n",
    "    q_p_ids = list(q_to_p_dict[q_id].keys())\n",
    "\n",
    "    for q_p_id in q_p_ids:\n",
    "        results.append(convert_to_json(q_text, p_dict[q_p_id], 1, separator))\n",
    "        \n",
    "    fts_results = utils.find_for_phrase_with_exclusion(index_url, q_text, 'text', 3*len(q_p_ids), q_p_ids)\n",
    "    for fts_result_id in fts_results:\n",
    "        results.append(convert_to_json(q_text, p_dict[fts_result_id], 0, separator))\n",
    "\n",
    "def convert_to_json(q_text, p_text, label, separator):\n",
    "    return {\n",
    "            \"text\": f\"{q_text}{separator}{p_text}\",\n",
    "            \"label\": label,\n",
    "        }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = collect_training_dataset(train_index_url, no_vate_corpus_dict, ['train'], separator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_dataset = collect_training_dataset(validation_index_url, va_corpus_dict, ['validation'], separator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (0/1 shards):   0%|          | 0/56664 [00:00<?, ? examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 56664/56664 [00:00<00:00, 386170.68 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 4952/4952 [00:00<00:00, 182805.63 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "datasets = DatasetDict({\"train\": train_dataset, \"validation\": validation_dataset})\n",
    "datasets.save_to_disk(\"./question-passage-classification\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Przygotowanie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 56664/56664 [00:12<00:00, 4555.78 examples/s]\n",
      "Map: 100%|██████████| 4952/4952 [00:01<00:00, 4056.93 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 56664\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return pl_tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = datasets.map(tokenize_function, batched=True)\n",
    "tokenized_datasets[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Co jest uważane za wydatek służbowy w podróży służbowej?</s>Wytyczne IRS dotyczące tematu. Ogólnie rzecz biorąc, najlepsze, co mogę powiedzieć, to to, że Twój wydatek biznesowy może podlegać odliczeniu. Ale to zależy od okoliczności i tego, co chcesz odliczyć. Podróże Podatnicy, którzy wyjeżdżają z domu w celach służbowych, mogą odliczyć związane z tym wydatki, w tym koszty dotarcia do miejsca docelowego, koszty zakwaterowania i wyżywienia oraz inne zwykłe i niezbędne wydatki. Podatnicy są uważani za „wyjeżdżających poza dom”, jeśli ich obowiązki wymagają od nich przebywania poza domem znacznie dłużej niż zwykły dzień pracy i muszą spać lub odpoczywać, aby sprostać wymogom pracy. Można odliczyć rzeczywisty koszt posiłków i nieprzewidziane wydatki lub skorzystać ze standardowej diety żywieniowej i obniżonych wymogów ewidencji. Niezależnie od zastosowanej metody odliczenia posiłków są zazwyczaj ograniczone do 50 procent, jak wspomniano wcześniej. Jako koszt można zgłaszać tylko rzeczywiste koszty zakwaterowania, a rachunki należy przechowywać do dokumentacji. Wydatki muszą być rozsądne i odpowiednie; potrącenia z tytułu nadmiernych wydatków nie są dopuszczalne. Więcej informacji można znaleźć w publikacji 463, Podróże, rozrywka, prezenty i wydatki na samochód. Rozrywka Wydatki na rozrywkę dla klientów, klientów lub pracowników mogą być odliczane, jeśli są one zarówno zwyczajne, jak i konieczne oraz spełniają jeden z następujących testów: Test bezpośrednio związany: Głównym celem działalności rozrywkowej jest prowadzenie działalności, działalność była faktycznie prowadzona podczas działalność i podatnik mieli więcej niż ogólne oczekiwanie uzyskania dochodu lub innej konkretnej korzyści biznesowej w przyszłości. Powiązany test: rozrywka była związana z aktywnym prowadzeniem działalności handlowej lub biznesowej podatnika i miała miejsce bezpośrednio przed lub po istotnej dyskusji biznesowej. Publikacja 463 zawiera obszerniejsze wyjaśnienie tych testów, jak również innych ograniczeń i wymagań dotyczących odliczania wydatków na rozrywkę. Prezenty Podatnicy mogą odliczyć część lub całość kosztów prezentów wręczanych w ramach ich działalności handlowej lub biznesowej. Ogólnie rzecz biorąc, odliczenie jest ograniczone do 25 USD za prezenty wręczane bezpośrednio lub pośrednio jednej osobie w ciągu roku podatkowego. Więcej omówienia zasad i ograniczeń można znaleźć w Publikacji 463. Jeśli Twoja spółka LLC zwróci Ci wydatki wykraczające poza te wytyczne, należy je traktować jako dochód dla celów podatkowych. Edytuj koszty posiłków: Kwota standardowego dodatku na posiłki. Standardowy dodatek na posiłki to federalna stawka M&IE. W przypadku podróży w 2010 r. stawka dla większości małych miejscowości w Stanach Zjednoczonych wynosi 46 USD dziennie. Źródło IRS P463 Alternatywnie możesz dokonać zwrotu według stawki dziennej\n",
      "[0, 3407, 2092, 39104, 2163, 23004, 11418, 2348, 1019, 10273, 45454, 1550, 2, 2331, 4603, 45, 19295, 5666, 16094, 1899, 38126, 4662, 13786, 1947, 9104, 1947, 2249, 5492, 4041, 1947, 2063, 2063, 1947, 2040, 22761, 23004, 6596, 11088, 2402, 36663, 21386, 4068, 1899, 2894, 2063, 6466, 2173, 11056, 1009, 2210, 1947, 2249, 13792, 43844, 1899, 2579, 19886, 38900, 2510, 1947, 2634, 28991, 1046, 3537, 1019, 24173, 25502, 1947, 3065, 43844, 5307, 1046, 2194, 10166, 1947, 1019, 2194, 6159, 7578, 2333, 2041, 3845, 33663, 2512, 1947, 6159, 26226, 9578, 1009, 20440, 4397, 2248, 3914, 22717, 1009, 11434, 10166, 1899, 38900, 2510, 2264, 3329, 2572, 2163, 1791, 10138, 3862, 4445, 5157, 1956, 1947, 3346, 2186, 11137, 13899, 2173, 2531, 45946, 4445, 16713, 4432, 7847, 2876, 17533, 3501, 2631, 1009, 4730, 17088, 2491, 14714, 2726, 1947, 2802, 29335, 15040, 14229, 2631, 1899, 5354, 43844, 48244, 8890, 28069, 1009, 2013, 21070, 10166, 2491, 8981, 2343, 6740, 11577, 21308, 30022, 6910, 1009, 9997, 2589, 17834, 20116, 1899, 23897, 2173, 6171, 4695, 11244, 21386, 2700, 28069, 2264, 10307, 22454, 2041, 2693, 5195, 1947, 2217, 7640, 2890, 3695, 1899, 6843, 8890, 2545, 16451, 2308, 36870, 6159, 26226, 9578, 1947, 1011, 18567, 3406, 13465, 2726, 2041, 14348, 1899, 44001, 4730, 2458, 14482, 2079, 1009, 10161, 1195, 17877, 4081, 1046, 6234, 12631, 2089, 9752, 1997, 2264, 34310, 1899, 10249, 4338, 2545, 5378, 1019, 14020, 24, 5783, 1947, 2579, 19886, 1947, 11932, 6958, 1947, 24274, 1009, 10166, 1998, 6704, 1899, 44942, 6958, 44001, 1998, 11932, 14335, 2211, 7128, 1947, 7128, 2491, 4424, 3065, 2458, 2021, 2519, 2414, 1947, 3346, 2264, 2290, 4635, 10073, 2079, 1947, 2217, 1009, 10375, 2248, 23352, 3247, 1046, 22358, 26641, 1335, 39309, 7616, 10743, 1335, 11692, 7432, 4654, 19695, 4137, 2092, 4649, 4654, 1947, 5142, 2663, 11782, 11786, 3095, 5142, 1009, 39055, 4153, 2944, 2876, 18991, 18687, 10521, 16776, 2491, 8049, 24278, 10948, 6596, 8906, 1019, 6174, 1899, 52, 2945, 2003, 2067, 14825, 1335, 11932, 6958, 2663, 13413, 1046, 43885, 16481, 4654, 25243, 2491, 6596, 8906, 29951, 1009, 3943, 2963, 7616, 2534, 2491, 2184, 4666, 2130, 6204, 6596, 8906, 1899, 6787, 20292, 24, 5783, 9138, 15150, 3955, 18880, 2513, 26641, 1947, 2217, 2604, 3112, 18609, 1009, 20702, 7371, 21386, 6819, 9752, 1998, 11932, 14335, 1899, 16244, 2162, 38900, 2510, 3065, 43844, 3865, 2491, 13680, 6510, 38641, 5004, 1988, 2826, 1019, 4300, 2186, 4654, 25243, 2491, 6596, 8906, 1899, 38126, 4662, 13786, 1947, 21386, 2824, 2092, 22454, 2041, 2698, 20123, 2163, 24274, 5004, 39803, 7616, 2491, 24424, 4192, 14507, 1019, 3747, 2254, 23934, 1899, 10249, 83, 17304, 8045, 1009, 18609, 2545, 5378, 1019, 6787, 4712, 24, 5783, 1899, 3484, 13462, 10160, 48, 48, 1023, 32547, 7086, 10166, 23787, 43725, 4445, 2322, 48866, 1947, 3406, 2193, 16217, 2628, 13131, 2211, 10664, 15415, 1899, 12828, 41956, 6159, 28069, 1335, 33892, 6740, 13975, 10276, 1998, 25520, 1899, 27336, 10962, 11080, 1998, 25520, 2063, 11098, 18957, 20941, 1058, 1664, 12065, 1899, 1049, 3714, 10273, 1019, 9441, 1024, 1899, 20941, 2211, 6043, 7918, 6020, 1019, 13531, 9034, 5979, 3523, 20123, 9216, 1899, 23301, 45, 19295, 52, 24, 5783, 34465, 17643, 11814, 12241, 13452, 2]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "<s>|Co</w>|jest</w>|uważane</w>|za</w>|wydatek</w>|służb|owy</w>|w</w>|podróży</w>|służbowej</w>|?</w>|</s>|Wy|tyczne</w>|I|RS</w>|dotyczące</w>|tematu</w>|.</w>|Ogólnie</w>|rzecz</w>|biorąc</w>|,</w>|najlepsze</w>|,</w>|co</w>|mogę</w>|powiedzieć</w>|,</w>|to</w>|to</w>|,</w>|że</w>|Twój</w>|wydatek</w>|bizne|sowy</w>|może</w>|podlegać</w>|odli|czeniu</w>|.</w>|Ale</w>|to</w>|zależy</w>|od</w>|okoliczności</w>|i</w>|tego</w>|,</w>|co</w>|chcesz</w>|odliczyć</w>|.</w>|Pod|róże</w>|Podat|nicy</w>|,</w>|którzy</w>|wyjeżdżają</w>|z</w>|domu</w>|w</w>|celach</w>|służbowych</w>|,</w>|mogą</w>|odliczyć</w>|związane</w>|z</w>|tym</w>|wydatki</w>|,</w>|w</w>|tym</w>|koszty</w>|dotar|cia</w>|do</w>|miejsca</w>|docel|owego</w>|,</w>|koszty</w>|zakwate|rowania</w>|i</w>|wyży|wienia</w>|oraz</w>|inne</w>|zwykłe</w>|i</w>|niezbędne</w>|wydatki</w>|.</w>|Podat|nicy</w>|są</w>|uważ|ani</w>|za</w>|„</w>|wyjeżdż|ających</w>|poza</w>|dom</w>|”</w>|,</w>|jeśli</w>|ich</w>|obowiązki</w>|wymagają</w>|od</w>|nich</w>|przebywania</w>|poza</w>|domem</w>|znacznie</w>|dłużej</w>|niż</w>|zwykły</w>|dzień</w>|pracy</w>|i</w>|muszą</w>|spać</w>|lub</w>|odpoczy|wać</w>|,</w>|aby</w>|sprostać</w>|wymo|gom</w>|pracy</w>|.</w>|Można</w>|odliczyć</w>|rzeczywisty</w>|koszt</w>|posiłków</w>|i</w>|nie|przewidziane</w>|wydatki</w>|lub</w>|skorzystać</w>|ze</w>|standar|dowej</w>|diety</w>|żywie|niowej</w>|i</w>|obniż|onych</w>|wymogów</w>|ewidencji</w>|.</w>|Niezależnie</w>|od</w>|zastos|owanej</w>|metody</w>|odli|czenia</w>|posiłków</w>|są</w>|zazwyczaj</w>|ograniczone</w>|do</w>|50</w>|procent</w>|,</w>|jak</w>|wspomni|ano</w>|wcześniej</w>|.</w>|Jako</w>|koszt</w>|można</w>|zgłaszać</w>|tylko</w>|rzeczywiste</w>|koszty</w>|zakwate|rowania</w>|,</w>|a</w>|rachunki</w>|należy</w>|przechowy|wać</w>|do</w>|dokumentacji</w>|.</w>|Wydatki</w>|muszą</w>|być</w>|rozsąd|ne</w>|i</w>|odpowiednie</w>|;</w>|potrą|cenia</w>|z</w>|tytułu</w>|nadmier|nych</w>|wydatków</w>|nie</w>|są</w>|dopuszczalne</w>|.</w>|Więcej</w>|informacji</w>|można</w>|znaleźć</w>|w</w>|publikacji</w>|4|63</w>|,</w>|Pod|róże</w>|,</w>|rozry|wka</w>|,</w>|prezenty</w>|i</w>|wydatki</w>|na</w>|samochód</w>|.</w>|Rozry|wka</w>|Wydatki</w>|na</w>|rozry|wkę</w>|dla</w>|klientów</w>|,</w>|klientów</w>|lub</w>|pracowników</w>|mogą</w>|być</w>|od|licz|ane</w>|,</w>|jeśli</w>|są</w>|one</w>|zarówno</w>|zwyczaj|ne</w>|,</w>|jak</w>|i</w>|konieczne</w>|oraz</w>|spełniają</w>|jeden</w>|z</w>|następujących</w>|testów</w>|:</w>|Test</w>|bezpośrednio</w>|związany</w>|:</w>|Głównym</w>|celem</w>|działalności</w>|rozryw|kowej</w>|jest</w>|prowadzenie</w>|działalności</w>|,</w>|działalność</w>|była</w>|faktycznie</w>|prowadzona</w>|podczas</w>|działalność</w>|i</w>|podatnik</w>|mieli</w>|więcej</w>|niż</w>|ogólne</w>|oczekiwanie</w>|uzyskania</w>|dochodu</w>|lub</w>|innej</w>|konkretnej</w>|korzyści</w>|bizne|sowej</w>|w</w>|przyszłości</w>|.</w>|P|owią|za|ny</w>|test</w>|:</w>|rozry|wka</w>|była</w>|związana</w>|z</w>|aktywnym</w>|prowadzeniem</w>|działalności</w>|handlowej</w>|lub</w>|bizne|sowej</w>|podatnika</w>|i</w>|miała</w>|miejsce</w>|bezpośrednio</w>|przed</w>|lub</w>|po</w>|istot|nej</w>|dyskusji</w>|bizne|sowej</w>|.</w>|Publi|kacja</w>|4|63</w>|zawiera</w>|obszer|niejsze</w>|wyjaśnienie</w>|tych</w>|testów</w>|,</w>|jak</w>|również</w>|innych</w>|ograniczeń</w>|i</w>|wymagań</w>|dotyczących</w>|odli|czania</w>|wydatków</w>|na</w>|rozry|wkę</w>|.</w>|Prezen|ty</w>|Podat|nicy</w>|mogą</w>|odliczyć</w>|część</w>|lub</w>|całość</w>|kosztów</w>|prezentów</w>|wrę|cz|anych</w>|w</w>|ramach</w>|ich</w>|działalności</w>|handlowej</w>|lub</w>|bizne|sowej</w>|.</w>|Ogólnie</w>|rzecz</w>|biorąc</w>|,</w>|odli|czenie</w>|jest</w>|ograniczone</w>|do</w>|25</w>|USD</w>|za</w>|prezenty</w>|wrę|czane</w>|bezpośrednio</w>|lub</w>|pośrednio</w>|jednej</w>|osobie</w>|w</w>|ciągu</w>|roku</w>|podatkowego</w>|.</w>|Więcej</w>|o|mówienia</w>|zasad</w>|i</w>|ograniczeń</w>|można</w>|znaleźć</w>|w</w>|Publi|kacji</w>|4|63</w>|.</w>|Jeśli</w>|Twoja</w>|spółka</w>|L|L|C</w>|zwróci</w>|Ci</w>|wydatki</w>|wykra|czające</w>|poza</w>|te</w>|wytyczne</w>|,</w>|należy</w>|je</w>|traktować</w>|jako</w>|dochód</w>|dla</w>|celów</w>|podatkowych</w>|.</w>|Edy|tuj</w>|koszty</w>|posiłków</w>|:</w>|Kwota</w>|standar|dowego</w>|dodatku</w>|na</w>|posiłki</w>|.</w>|Standar|dowy</w>|dodatek</w>|na</w>|posiłki</w>|to</w>|fede|ralna</w>|stawka</w>|M</w>|&</w>|IE</w>|.</w>|W</w>|przypadku</w>|podróży</w>|w</w>|2010</w>|r</w>|.</w>|stawka</w>|dla</w>|większości</w>|małych</w>|miejscowości</w>|w</w>|Stanach</w>|Zjednoczonych</w>|wynosi</w>|46</w>|USD</w>|dziennie</w>|.</w>|Źródło</w>|I|RS</w>|P|4|63</w>|Alterna|tywnie</w>|możesz</w>|dokonać</w>|zwrotu</w>|</s>\n",
      "512\n",
      "512\n"
     ]
    }
   ],
   "source": [
    "example = tokenized_datasets[\"train\"][0]\n",
    "print(example[\"text\"])\n",
    "print(example[\"input_ids\"])\n",
    "print(example[\"attention_mask\"])\n",
    "print(\"|\".join(pl_tokenizer.convert_ids_to_tokens(list(example[\"input_ids\"]))))\n",
    "\n",
    "print(len([e for e in example[\"input_ids\"] if e != 1]))\n",
    "print(len([e for e in example[\"attention_mask\"] if e == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allegro/herbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(50000, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"allegro/herbert-base-cased\", num_labels=2\n",
    ")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "arguments = TrainingArguments(\n",
    "    output_dir=\"./output\",\n",
    "    do_train=True,\n",
    "    do_eval=True,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=300,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=5e-05,\n",
    "    num_train_epochs=1,\n",
    "    logging_first_step=True,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=50,\n",
    "    save_strategy=\"epoch\",\n",
    "    fp16=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "\n",
    "metric = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=arguments,\n",
    "    train_dataset=tokenized_datasets[\"train\"].shuffle(seed=42),\n",
    "    eval_dataset=tokenized_datasets[\"validation\"].shuffle(seed=42),\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 48284), started 18:13:54 ago. (Use '!kill 48284' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-1c80317fa3b1799d\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-1c80317fa3b1799d\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir gdrive/MyDrive/poquad/output/runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'lab5_utils' from '/Users/mwardynski/Documents/ds/_semestr_9/przetwarzanie_jezyka_naturalnego/labs/lab5/lab5_utils.py'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import lab5_utils\n",
    "importlib.reload(lab5_utils)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
