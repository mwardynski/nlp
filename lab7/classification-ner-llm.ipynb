{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Marcin Wardyński  \n",
    "czwartek, 8:00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mwardynski/Documents/ds/_semestr_9/przetwarzanie_jezyka_naturalnego/labs/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "seed = 7\n",
    "passage_number = 1000\n",
    "\n",
    "corpus = load_dataset(\"clarin-knext/fiqa-pl\", name=\"corpus\")\n",
    "passages = corpus['corpus'].shuffle(seed=seed).select(range(passage_number))['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przy opracowywaniu prompt-a:\n",
    "- użyj szablonu\n",
    "- dopasuj treść prompta\n",
    "- jeśli to konieczne użyj kontraprzykładu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klasy NER-ów:\n",
    "- PER\n",
    "- ORG\n",
    "- GPE\n",
    "- LOC\n",
    "- DATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import hashlib\n",
    "from diskcache import Cache\n",
    "from functools import lru_cache\n",
    "\n",
    "OLLAMA_SERVER_URL = \"http://localhost:11434\"\n",
    "cache = Cache(\"ollama_cache\")\n",
    "\n",
    "@lru_cache(maxsize=1100)\n",
    "def ask_ollama_with_memory_cache(model, prompt):\n",
    "    return ask_ollama_with_disk_cache(model, prompt)\n",
    "\n",
    "def ask_ollama_with_disk_cache(model, prompt):\n",
    "    \n",
    "    cache_key = hashlib.sha256((model+prompt).encode()).hexdigest()\n",
    "    \n",
    "    if cache_key in cache:\n",
    "        answer = cache[cache_key]\n",
    "        return (1, answer)\n",
    "    else:\n",
    "        answer = ask_ollama_server(model, prompt)\n",
    "        cache[cache_key] = answer\n",
    "        return (0, answer)\n",
    "\n",
    "\n",
    "def ask_ollama_server(model, prompt):\n",
    "    url = f\"{OLLAMA_SERVER_URL}/api/generate\"\n",
    "    \n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"prompt\": prompt,\n",
    "        \"stream\": False\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.post(url, json=payload)\n",
    "        response.raise_for_status()\n",
    "        data = response.json()\n",
    "        return data[\"response\"]\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(73480) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pl-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/pl_core_news_sm-3.8.0/pl_core_news_sm-3.8.0-py3-none-any.whl (20.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.2/20.2 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pl-core-news-sm\n",
      "Successfully installed pl-core-news-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('pl_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download pl_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pl_core_news_sm\n",
    "\n",
    "nlp = pl_core_news_sm.load()\n",
    "\n",
    "def find_named_entities_spacy(passage):\n",
    "    results = {\"persName\": [],\n",
    "                \"orgName\": [],\n",
    "                \"placeName\": [],\n",
    "                \"geogName\": [],\n",
    "                \"date\": [],\n",
    "                \"time\": []}\n",
    "\n",
    "    doc = nlp(passage)\n",
    "    for ent in doc.ents:\n",
    "        results[ent.label_].append(str(ent))\n",
    "    \n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'persName': ['G.', 'Edward Griffin'],\n",
       " 'orgName': ['The Creature From Jekyll Island'],\n",
       " 'placeName': [],\n",
       " 'geogName': [],\n",
       " 'date': [],\n",
       " 'time': []}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_named_entities_spacy(passages[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' W podanym tekście nie ma takiej liczby nazw własnych, która mogłaby być sklasyfikowana do trzech kategorii: osoba, organizacja, miejsce. Jednak można wyodrębnić kilka nawiązujących do osób i instytucji:\\n\\n1. \"G. Edward Griffin\" – ten jest autorem książki \"The Creature From Jekyll Island\", która jest wymieniona w tekście.\\n2. \"rząd federalny\" - to nawiązuje do instytucji rządowej, której działania są opisane w treści.\\n3. W innych fragmentach tekstu można odnaleźć aluzje do innych osób i instytucji, ale bez imiennych wskaźników (np. \"fajne rzeczy\", które rząd chce kupić; \"nowe czołgi lub samoloty\" itp.).'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"między znakami >>> i <<< znajduje się tekst, w którym masz odnaleźć nazwy własne i zaklasyfikować do jednej trzech kategorii: osoba, organizacja, miejsce, wynik przestaw jako json >>>„Chociaż jest tu kilka dobrych uwag dotyczących przyczyny inflacji (głównie związanych z podażą i popytem), azcoastal zmierza w innym kierunku, który ja sam zamierzałem obrać. Pozwólcie jednak, że podam inny punkt widzenia. Inną przyczyną inflacji jest drukowanie pieniędzy przez rząd (nie tylko zastąpienie starych pieniędzy nowymi, ale dodanie do całkowitej ilości pieniądza w obiegu).Jeśli rząd podwoi ilość pieniądza w obiegu (ze względu na argumenty i łatwą matematykę). ), wartość wszystkich pieniędzy spada dwukrotnie. To jest inflacja i jak to ujął G. Edward Griffin w The Creature From Jekyll Island, jest to tak naprawdę równoznaczne z ukrytym podatkiem. Krótko mówiąc, rząd federalny chce kupują fajne rzeczy, takie jak nowe czołgi lub samoloty, albo chcą dać kilka kartek żywnościowych biednym ludziom, albo chcą latać prywatnymi odrzutowcami, ale nie mają wystarczającej ilości pieniędzy z podatków. i wydawać je i kupować ich rzeczy. Ponieważ oni Właśnie zwiększyłem ilość pieniądza w obiegu, jednak pieniądz traci na wartości. Na przykład Twoje oszczędności straciły na wartości o połowę, pomimo tego, że na Twoim koncie oszczędnościowym znajduje się taka sama liczba dolarów. To tylko sposób, w jaki rząd może cię opodatkować bez nakładania na ciebie podatków. Kupują rzeczy, a ty masz teraz mniej pieniędzy (tzn. twoja emerytura jest mniej warta) i nawet nie wiesz, że właśnie zostałeś opodatkowany. Robi mi się niedobrze, że pozwoliliśmy naszym „przywódcom” ujść z tym na sucho”.'<<<\"\n",
    "\n",
    "ask_ollama_server(model, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' {\\n    \"Osoba\": [\"Zależy\"],\\n    \"Nazwa geograficzna\": [],\\n    \"Organizacja\": [],\\n    \"Miejsce\": []\\n}'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"między znakami >>> i <<< znajduje się tekst, w którym masz odnaleźć nazwy własne i zaklasyfikować do jednej z trzech kategorii: osoba, organizacja, miejsce, nazwa geograficzna, wynik przestaw jako json >>>'Zależy, co rozumiesz przez komunizm. Inną kwestią jest również to, czy dochód podstawowy jest opłacalny, czy nie. Nie mówię, że znam wszystkie odpowiedzi, ale dużo myślałem o przyszłości. Niektórzy obawiają się, że dochód podstawowy w zasadzie uczyniłby masy niewolnikami w pewien sposób, ponieważ nie rozwiąże nierówności w dochodach, sprawi, że ludzie będą zależni od pomocy rządowej. Inną opcją jest rozproszenie pracy. Zamiast pracować 40 godzin tygodniowo, pracują 30, 20 lub mniej. Ale to rozwiązanie może być tylko tymczasowe, dopóki ludzie nie będą po prostu nieopłacalni. Pojawi się pytanie, dlaczego pracujemy i po co tworzymy maszyny? Odciążyć ludzką pracę i służyć ludzkiemu życiu? Albo wydobyć jak najwięcej z Ziemi bez względu na ludzkie życie, zgromadzić wielki stos zasobów bez względu na to, czy istnieją ludzie, aby z nich korzystać.'<<<.\"\n",
    "\n",
    "ask_ollama_server(model, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' {\\n \"osoba\": [\"ty\"],\\n \"nazwa geograficzna\": [],\\n \"miejsce\": [],\\n \"organizacja\": []\\n}'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"między znakami >>> i <<< znajduje się tekst, w którym masz odnaleźć nazwy własne i zaklasyfikować do jednej z trzech kategorii: osoba, organizacja, miejsce, nazwa geograficzna, wynik przestaw jako json >>>'Zależy, co rozumiesz przez komunizm. Inną kwestią jest również to, czy dochód podstawowy jest opłacalny, czy nie. Nie mówię, że znam wszystkie odpowiedzi, ale dużo myślałem o przyszłości. Niektórzy obawiają się, że dochód podstawowy w zasadzie uczyniłby masy niewolnikami w pewien sposób, ponieważ nie rozwiąże nierówności w dochodach, sprawi, że ludzie będą zależni od pomocy rządowej. Inną opcją jest rozproszenie pracy. Zamiast pracować 40 godzin tygodniowo, pracują 30, 20 lub mniej. Ale to rozwiązanie może być tylko tymczasowe, dopóki ludzie nie będą po prostu nieopłacalni. Pojawi się pytanie, dlaczego pracujemy i po co tworzymy maszyny? Odciążyć ludzką pracę i służyć ludzkiemu życiu? Albo wydobyć jak najwięcej z Ziemi bez względu na ludzkie życie, zgromadzić wielki stos zasobów bez względu na to, czy istnieją ludzie, aby z nich korzystać.'<<<. Odpowiedz wyłącznie żądanym json i nic ponad to\"\n",
    "\n",
    "ask_ollama_server(model, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' {\\n \"osoby\": [\"Osoba nieznana\"],\\n \"organizacje\": [],\\n \"miejsca\": []\\n}'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Na podstawie tekstu między znakami >>> i <<< znajdź nazwy własne i zaklasyfikować do jednej z trzech kategorii: osoba, organizacja, miejsce: >>>'Zależy, co rozumiesz przez komunizm. Inną kwestią jest również to, czy dochód podstawowy jest opłacalny, czy nie. Nie mówię, że znam wszystkie odpowiedzi, ale dużo myślałem o przyszłości. Niektórzy obawiają się, że dochód podstawowy w zasadzie uczyniłby masy niewolnikami w pewien sposób, ponieważ nie rozwiąże nierówności w dochodach, sprawi, że ludzie będą zależni od pomocy rządowej. Inną opcją jest rozproszenie pracy. Zamiast pracować 40 godzin tygodniowo, pracują 30, 20 lub mniej. Ale to rozwiązanie może być tylko tymczasowe, dopóki ludzie nie będą po prostu nieopłacalni. Pojawi się pytanie, dlaczego pracujemy i po co tworzymy maszyny? Odciążyć ludzką pracę i służyć ludzkiemu życiu? Albo wydobyć jak najwięcej z Ziemi bez względu na ludzkie życie, zgromadzić wielki stos zasobów bez względu na to, czy istnieją ludzie, aby z nich korzystać.'<<<. Odpowiedz obiektem json w z polami: osoby, organizacje, miejsca\"\n",
    "\n",
    "ask_ollama_server(model, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dzięki za artykuły z wiadomościami. Być może mógłbyś wziąć pod uwagę to [badanie Narodowego Instytutu Zdrowia](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1253709/), które przyglądało się badaniu NHS, które wciąż przytaczasz? W szczególności >Ekspozycja na glifosat nie była związana z ogólną zachorowalnością na raka ani z większością badanych przez nas podtypów raka. Sugerowano związek z występowaniem szpiczaka mnogiego [raka komórek plazmatycznych], który należy monitorować, ponieważ więcej przypadków występuje w AHS. Czy nie należy tego również brać pod uwagę, gdy mówimy o tym, czy Round-up powoduje raka? W tym momencie nauka wydaje się daleka od ugruntowania. Wszystko, co połączyłeś, dotyczy chłoniaka nieziarniczego. Rozumiem, dlaczego Monsanto zignorowało dane, które wskazują na problem, i skupiło się na tym pojedynczym, właśnie analizowanym badaniu. Dlaczego jesteś?'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = find_names_entities(passages[1:2])[0][0]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' {\\n    \"osoba\": [],\\n    \"organizacja\": [\"Narodowy Instytut Zdrowia\", \"Monsanto\"],\\n    \"miejsce\": []\\n  }'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"Przeanalizuj podany tekst i wypisz nazwy własne podzielone na kategorie: osoby, organizacje, miejsca. Twoja odpowiedź powinna składać się wyłącznie z obiektu JSON o formacie zdefiniowanym poniżej. Jeśli pewna kategoria nie ma odnalezionych reprezentantów, zwróć dla niej pustą tablicę. Upewnij się, że wynik jest czysty i zawiera wyłącznie obiekt JSON\\n\" +\\\n",
    "\"Format JSON:\\n\" +\\\n",
    "\"{'osoba': [\\\"lista osób\\\"],  \\\"organizacja\\\": [\\\"lista organizacji\\\"], \\\"miejsce\\\": [\\\"lista miejsc\\\"]}\\n\"+\\\n",
    "\"Tekst wejściowy:\\n\"+\\\n",
    "\"\\\"\"+text+\"\\\"\\n\"+\\\n",
    "\"Wynik:\"\n",
    "\n",
    "ask_ollama_server(model_mistral, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 3257.7920219898224s\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for passage in passages:\n",
    "\n",
    "    prompt = \"Przeanalizuj podany tekst i wypisz nazwy własne podzielone na kategorie: osoby, organizacje, nazwy administracyjne miejsc, nazwy geograficzne, daty, czas. Twoja odpowiedź powinna składać się wyłącznie z obiektu JSON o formacie zdefiniowanym poniżej. Jeśli pewna kategoria nie ma odnalezionych reprezentantów, zwróć dla niej pustą listę. Upewnij się, że wynik jest czysty i zawiera wyłącznie obiekt JSON\\n\" +\\\n",
    "    \"Format JSON:\\n\" +\\\n",
    "    \"{'persName': [\\\"lista osób\\\"],  \\\"orgName\\\": [\\\"lista organizacji\\\"], \\\"placeName\\\": [\\\"lista nazw administracyjnych miejsc\\\"], \\\"geog\\\": [\\\"lista nazw geograficznych\\\"], \\\"date\\\": [\\\"lista dat\\\"], \\\"time\\\": [\\\"lista określeń czasu\\\"]}\\n\"+\\\n",
    "    \"Tekst wejściowy:\\n\"+\\\n",
    "    \"\\\"\"+passage+\"\\\"\\n\"+\\\n",
    "    \"Wynik:\"\n",
    "\n",
    "    ask_ollama_with_disk_cache(model_mistral, prompt)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Elapsed time: {elapsed_time}s\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_intro = \"Przeanalizuj podany tekst i wypisz nazwy własne podzielone na kategorie: osoby, organizacje, nazwy administracyjne miejsc, nazwy geograficzne, daty, czas. Twoja odpowiedź powinna składać się wyłącznie z obiektu JSON o formacie zdefiniowanym poniżej. Jeśli pewna kategoria nie ma odnalezionych reprezentantów, zwróć dla niej pustą listę. Upewnij się, że wynik jest czysty i zawiera wyłącznie obiekt JSON\\n\"\n",
    "prompt_json_format = \"Format JSON:\\n{'persName': [\\\"lista osób\\\"],  \\\"orgName\\\": [\\\"lista organizacji\\\"], \\\"placeName\\\": [\\\"lista nazw administracyjnych miejsc\\\"], \\\"geog\\\": [\\\"lista nazw geograficznych\\\"], \\\"date\\\": [\\\"lista dat\\\"], \\\"time\\\": [\\\"lista określeń czasu\\\"]}\\n\"\n",
    "prompt_output = \"Wynik:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 3200.7369158267975s\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for passage in passages:\n",
    "    prompt_input = f\"Tekst wejściowy:\\n\\\"{passage}\\\"\\n\"\n",
    "    prompt = prompt_intro + prompt_json_format + prompt_input + prompt_output\n",
    "        \n",
    "    ask_ollama_with_disk_cache(model_mistral, prompt)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Elapsed time: {elapsed_time}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "example1_text = \"Czy możesz mi pokazać gdzie? Ponieważ z pewnością, kiedy Obama nałożył podatek na finansowanie ACA, gospodarka rozkwitła, zatrudniono milion lekarzy, setki szpitali i tysiące spacerów w klinikach, które zbudowaliśmy. A giełda rozwijała się bardziej.\"\n",
    "example1_answer = \"{'persName': [\\\"Obama\\\"],  \\\"orgName\\\": [\\\"ACA\\\"], \\\"placeName\\\": [], \\\"geogName\\\": [], \\\"date\\\": [], \\\"time\\\": []}\"\n",
    "\n",
    "example2_text = \"„Postęp komputerowy w coraz większym stopniu pozwala producentom dostosowywać zamówienia i szybciej wysyłać towary. W nowym świecie wytwarzanie produktów w odległych krajach o niskich płacach, takich jak Chiny, może być wadą: wysyłanie gotowych produktów do Stanów Zjednoczonych może trwać zbyt długo – tygodnie, miesiące. „Chodzi o bliskość z klientem” – powiedział Michael Mandel, główny strateg ekonomiczny w Progressive Policy Institute. „„Zdobędziesz trwałą i trwałą przewagę nad konkurencją zagraniczną”. który okupował Biały Dom. Mimo to prezydent Donald Trump skorzystał z okazji, by w środę wziąć udział w ogłoszeniu przez Foxconna, mówiąc, że „zdecydowanie” wydarzyło się z powodu jego wyboru i dążenia do cięć podatkowych i regulacyjnych. [źródło] ://hosted.ap.org/dynamic/stories/U/US_BC_US_AMAZON_AND_FOXCONN_SPEED_TO_CUSTOMERS?SITE=AP&SECTION=HOME&TEMPLATE=DEFAULT&CTIME=2017-07-27-03-16-36)\\\"\"\n",
    "example2_answer = \"{'persName': [\\\"Michael Mandel\\\", \\\"Donald Trump\\\"],  \\\"orgName\\\": [\\\"Progressive Policy Institute\\\", \\\"Biały Dom\\\", \\\"Foxconna\\\"], \\\"placeName\\\": [\\\"Chiny\\\", \\\"Stanów Zjednoczonych\\\"], \\\"geogName\\\": [], \\\"date\\\": [], \\\"time\\\": []}\"\n",
    "\n",
    "example3_text = \"„Płać za grę? Masz na myśli, że płacą za mocniejsze źródła danych, których inne firmy nie potrzebują, na pewno tak. Ale każdy może teraz handlować na giełdach amerykańskich (NYSE, NASDAQ, BATS itp.), co nie było prawdą 20 lat temu kiedy NYSE miała specjalistyczny monopol, więc tak, rynki są bardziej demokratyczne niż kiedykolwiek. Uwaga na marginesie, giełdy czerpią bezpośrednie zyski ze zwiększonego wolumenu obrotu, ponieważ przyjmują niewielki procent każdej transakcji, więc nie jestem pewien, co to znaczy, że nie czerpią z tego bezpośrednich korzyści. Mam też wrażenie, że nie rozumiesz zakresu działalności HFT, szczytowe zyski HFT były rzędu 7 miliardów w czasie największego wolumenu w ostatniej dekadzie (2005-2010 ). Są teraz około 1B. W porównaniu z bilionami dolarów, które zmieniają właściciela w ciągu roku, jest to kiepska wymiana, trudno nazwać „kran z darmowymi pieniędzmi”. Również Katsayuma otworzyła kolejną ciemną pulę, która obsługuje duże wolumeny klientów (twoich goldmans i merrils) Jedyną różnicą w IEX jest to, że ma darmową kampanię marketingową ign, aby przyciągnąć klientów. Poważnie, IEX jest niczym innym jak istniejącymi stałymi, krzyżowymi ciemnymi basenami, które przy okazji wkurzają inwestorów detalicznych bardziej niż oświetlone giełdy, takie jak NASDAQ. Katsayuma został zmiażdżony w swoich egzekucjach, ponieważ nie mógł nadążyć z czasem, a potem trafił w dziesiątkę, namawiając Michaela Lewisa, by namalował go jako „bohatera”, szczerze mówiąc, jestem zdziwiony, jakie szczęście miał ten koleś. Dealerzy brokerów BTW otrzymują preferencyjne traktowanie w IEX, co oznacza, że ​​mogą ciąć przed inwestorami detalicznymi. Dlaczego tak się na to zastanawiasz, czy wykonałeś kilka złych transakcji na eTrade i potrzebujesz kozła ofiarnego?”\"\n",
    "example3_answer = \"{'persName': [\\\"Katsayuma\\\", \\\"Katsayuma\\\", \\\"Michaela Lewisa\\\"],  \\\"orgName\\\": [\\\"NYSE\\\", \\\"NASDAQ\\\", \\\"BATS\\\", \\\"NYSE\\\", \\\"HFT\\\", \\\"goldmans\\\", \\\"merrils\\\", \\\"IEX\\\", \\\"ign\\\", \\\"IEX\\\", \\\"NASDAQ\\\", \\\"IEX\\\", \\\"eTrade\\\"], \\\"placeName\\\": [], \\\"geogName\\\": [], \\\"date\\\": [\\\"2005\\\", \\\"2010\\\"], \\\"time\\\": []}\"\n",
    "example2_full = f\"Przykład 3:\\n\\\"{example2_text}\\\"\\nOdpowiedź do przykładu 1:\\n\\\"{example2_answer}\\\"\\n\"\n",
    "\n",
    "example4_text = \"Nie zaczynaj od inwestowania w kilka pojedynczych firm. To ryzykowne. Chcesz przykładu? Myślę o dużej firmie, powiedzmy około 120 miliardów dolarów, znanej firmie i dobrych stałych dywidendach. Radzili sobie całkiem nieźle i generalnie byli zajęci przekonywaniem ludzi, że patrzą w przyszłość z nowymi, przyjaznymi dla środowiska technologiami. Potem... poszli i wylali garść ropy do Zatoki Meksykańskiej. Tak, to nie był ładny obraz, gdyby BP było tego dnia jedną z pięciu spółek w twoim portfelu. Sprawy wyglądałyby jednak znacznie lepiej, gdyby byli jedną z 500 lub 5000 firm. Więc. Po pierwsze, dążyć do dywersyfikacji za pośrednictwem funduszy inwestycyjnych lub ETF. (Osobiście uważam, że prawdopodobnie powinieneś zacząć od funduszy wzajemnych: po pierwsze unikasz opłat transakcyjnych. Łatwiej jest również umieścić średnie kwoty w dolarach w funduszach niż w ETF-ach, nawet jeśli otrzymujesz wolny od opłat handel ETF-ami. może dać ci lepsze wskaźniki wydatków, ale im mniej pieniędzy zainwestowałeś, tym mniej ważne.) Gdy masz przyzwoity portfel – dziesiątki tysięcy dolarów lub więcej – możesz zacząć rozważać posiadanie akcji poszczególnych spółek. Zwróć uwagę na opłaty, w tym opłaty transakcyjne / prowizje. Jeśli kupisz akcje o wartości 2000 USD i zapłacisz 20 USD prowizji, stracisz już 1%. Jeśli trzymasz fundusz powierniczy lub ETF, spójrz na wskaźnik wydatków. Roczna realna stopa zwrotu na giełdzie wynosi około 4%. (Prawdziwy zwrot jest po uwzględnieniu inflacji.) Jeśli Twoja opłata wynosi 1%, to około jedna czwarta Twoich zarobków, co jest ogromne. I chociaż funduszowi powierniczemu łatwo jest od czasu do czasu przewyższyć rynek o 1%, to naprawdę ciężko jest robić to konsekwentnie. Kiedy już przyjrzysz się poszczególnym firmom, powinieneś przeprowadzić wiele nieznośnych, nudnych, głupich poszukiwań, a nie kupować tylko akcji na podstawie ich marki. Będziesz zainteresowany kilkoma danymi. Głównym z nich jest prawdopodobnie wskaźnik P/E (cena/zysk). Jeśli weźmiesz odwrotność tego, uzyskasz wskaźnik, w jakim Twoja inwestycja przyniesie Ci pieniądze (np. P/E 20 to 5%, P/E 10 to 10%). Jeśli wszystko inne jest równe, niższy wskaźnik P/E jest dobrą rzeczą: oznacza to, że kupujesz dochód firmy naprawdę tanio. Jednak wszystko inne rzadko jest równe: jeśli akcje są naprawdę tanie, zwykle dzieje się tak dlatego, że inwestorzy nie myślą, że mają przed sobą długą przyszłość. Zarobki nie zawsze są spójne. Istnieje wiele innych miar, takich jak beta (korelacja z ogólnym rynkiem: bardziej ryzykowne akcje niestabilne mają wyższe wartości), marże brutto, cena do nielewarowanych wolnych przepływów pieniężnych i tym podobne. Ponownie wykonaj nudne badania, w przeciwnym razie po prostu grasz w gry ze swoimi pieniędzmi.\"\n",
    "example4_answer = \"{'persName': [],  \\\"orgName\\\": [\\\"BP\\\"], \\\"placeName\\\": [], \\\"geogName\\\": [\\\"Zatoki Meksykańskiej\\\"], \\\"date\\\": [], \\\"time\\\": []}\"\n",
    "\n",
    "example5_text = \"„To najlepszy tl;dr, jaki mogłem zrobić, [oryginał](https://www.bloomberg.com/news/articles/2017-08-22/hong-kong-braces-for-storm-hato-stock- handel może zostać zakłócony) zmniejszony o 73% (jestem botem) ***** > Hongkong podniósł poziom ostrzeżenia przed burzą do najwyższego poziomu po raz pierwszy od pięciu lat i odwołał poranną sesję handlową jako Poważna Tajfun Hato zbliżył się do centrum finansowego.> Jeśli sygnał będzie obowiązywał do południa, handel na czwartym co do wielkości rynku akcji na świecie zostanie dziś zlikwidowany, zgodnie z zasadami Hong Kong Exchanges & Clearing Ltd. > O godzinie 9 rano ciężki tajfun Hato znajdował się około 80 kilometrów na południe od Hongkongu, podało Obserwatorium.***** [**Rozszerzone podsumowanie**](http://np.reddit.com/r/autotldr/ komentarze/6vgq2t/hong_kong_delays_morning_trading_as_typhoon_hato/) | [FAQ](http://np.reddit.com/r/autotldr/comments/31b9fm/faq_autotldr_bot/ \\\"\\\"Wersja 1.65, ~196625 tl\\\");[do tej pory drs.\\\" Opinia](http://np.reddit.com/message/compose?to=%23autotldr \\\"\\\"PM i komentarze są monitorowane, mile widziane są konstruktywne opinie.\\\"\\\") | *Najlepsze* *Słowa kluczowe*: **Hong**^#1 **Kong**^#2 **Zamknij**^#3 **Tajfun**^#4 **Handel**^#5\\\"\"\n",
    "example5_answer = \"{'persName': [],  \\\"orgName\\\": [\\\"Hong Kong Exchanges & Clearing Ltd.\\\"], \\\"placeName\\\": [\\\"Hongkong\\\", \\\"Hongkongu\\\"], \\\"geogName\\\": [], \\\"date\\\": [], \\\"time\\\": [\\\"9 rano\\\"]}\"\n",
    "\n",
    "examples_text = [example1_text, example2_text, example3_text, example4_text, example5_text]\n",
    "examples_answer = [example1_answer, example2_answer, example3_answer, example4_answer, example5_answer]\n",
    "\n",
    "\n",
    "examples_snippet = []\n",
    "for i in range(len(examples_text)):\n",
    "    examples_snippet.append(f\"Przykład {i+1}:\\n\\\"{examples_text[i]}\\\"\\nOdpowiedź do przykładu {i+1}:\\n\\\"{examples_answer[i]}\\\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time: 10250.866141080856s\n"
     ]
    }
   ],
   "source": [
    "def perform_few_shot_prompt(passage):\n",
    "    prompt_input = f\"Tekst wejściowy:\\n\\\"{passage}\\\"\\n\"\n",
    "    prompt = prompt_intro + prompt_json_format + \"\".join(examples_snippet) + prompt_input + prompt_output\n",
    "        \n",
    "    result = ask_ollama_with_disk_cache(model_mistral, prompt)\n",
    "    return json.loads(result)\n",
    "    \n",
    "start_time = time.time()\n",
    "\n",
    "for passage in passages:\n",
    "    perform_few_shot_prompt(passage)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"Elapsed time: {elapsed_time}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#does single entry occures multiple times, like in the text\n",
    "\n",
    "def calculate_conf_matrix(baseline_entities, other_entities):\n",
    "    base_ents_tmp = baseline_entities[:]\n",
    "    other_ents_tmp = other_entities[:]\n",
    "\n",
    "    tp_list = []\n",
    "\n",
    "    for base_ent in baseline_entities:\n",
    "        if base_ent in other_ents_tmp:\n",
    "            base_ents_tmp.remove(base_ent)\n",
    "            other_ents_tmp.remove(base_ent)\n",
    "            tp_list.append(base_ent)\n",
    "\n",
    "    tp = len(tp_list)\n",
    "    fp = len(other_ents_tmp)\n",
    "    fn = len(base_ents_tmp)\n",
    "\n",
    "    return tp, fp, fn\n",
    "\n",
    "def calculate_precision_recall_f1_score(conf_matrix_by_class):\n",
    "    results = {}\n",
    "    for entity_class, conf_matrix in conf_matrix_by_class.items():\n",
    "        results[entity_class] = {}\n",
    "\n",
    "        precision = conf_matrix[\"TP\"]/(conf_matrix[\"TP\"]+conf_matrix[\"FP\"])\n",
    "        results[entity_class][\"precision\"] = precision\n",
    "\n",
    "        recall = conf_matrix[\"TP\"]/(conf_matrix[\"TP\"]+conf_matrix[\"FN\"])\n",
    "        results[entity_class][\"recall\"] = recall\n",
    "\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "        results[entity_class][\"f1_score\"] = f1_score\n",
    "\n",
    "def calculate_metrics(passages, baseline_fun, other_fun):\n",
    "    conf_matrix_by_class = {\"persName\": {\"TP\": 0, \"FP\": 0, \"FN\": 0},\n",
    "                                \"orgName\": {\"TP\": 0, \"FP\": 0, \"FN\": 0},\n",
    "                                \"placeName\": {\"TP\": 0, \"FP\": 0, \"FN\": 0},\n",
    "                                \"geogName\": {\"TP\": 0, \"FP\": 0, \"FN\": 0},\n",
    "                                \"date\": {\"TP\": 0, \"FP\": 0, \"FN\": 0},\n",
    "                                \"time\": {\"TP\": 0, \"FP\": 0, \"FN\": 0},\n",
    "                                \"total\": {\"TP\": 0, \"FP\": 0, \"FN\": 0}}\n",
    "    \n",
    "    for passage in passages:\n",
    "        results_baseline = baseline_fun(passage)\n",
    "        results_other = other_fun(passage)\n",
    "\n",
    "        for entity_class in results_baseline.keys():\n",
    "            baseline_entities = results_baseline[entity_class]\n",
    "            other_entities = results_other[entity_class]\n",
    "\n",
    "            tp, fp, fn = calculate_conf_matrix(baseline_entities, other_entities)\n",
    "\n",
    "            conf_matrix_by_class[entity_class][\"TP\"] += tp\n",
    "            conf_matrix_by_class[\"total\"][\"TP\"] += tp\n",
    "            conf_matrix_by_class[entity_class][\"FP\"] += fp\n",
    "            conf_matrix_by_class[\"total\"][\"FP\"] += fp\n",
    "            conf_matrix_by_class[entity_class][\"FN\"] += fn\n",
    "            conf_matrix_by_class[\"total\"][\"FN\"] += fn\n",
    "\n",
    "    return calculate_precision_recall_f1_score(conf_matrix_by_class)\n",
    "\n",
    "calculate_metrics(passages, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Czasy na przejście po wszystkich pasażach:\n",
    "\n",
    "Zero-Shot: 3200.7369158267975s ~53:20\n",
    "Few-Shot: 10250.866141080856s 2:50:50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Porównanie NER do LLM NER\n",
    "\n",
    "Czas, pamięć, miejsce na HDD, miejsce w pamięci i obciążenie CPU"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
